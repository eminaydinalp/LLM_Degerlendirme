[
  {
    "task_id": "B1_earthquake",
    "level": "B1",
    "word": "earthquake",
    "labeled_sentences": [
      [
        "Sentence A",
        "The city is prone to earthquakes, so we need to be prepared."
      ],
      [
        "Sentence B",
        "The earthquake caused a lot of damage to the city."
      ],
      [
        "Sentence C",
        "The earthquake destroyed many buildings in the city center."
      ],
      [
        "Sentence D",
        "The earthquake damaged many buildings in the city."
      ],
      [
        "Sentence E",
        "The earthquake caused a lot of damage."
      ],
      [
        "Sentence F",
        "Many people were scared during the recent earthquake."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "earthquake",
        "sentence": "The city is prone to earthquakes, so we need to be prepared."
      },
      "Sentence B": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "earthquake",
        "sentence": "The earthquake caused a lot of damage to the city."
      },
      "Sentence C": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "earthquake",
        "sentence": "The earthquake destroyed many buildings in the city center."
      },
      "Sentence D": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "earthquake",
        "sentence": "The earthquake damaged many buildings in the city."
      },
      "Sentence E": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "earthquake",
        "sentence": "The earthquake caused a lot of damage."
      },
      "Sentence F": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "earthquake",
        "sentence": "Many people were scared during the recent earthquake."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"earthquake\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: The city is prone to earthquakes, so we need to be prepared.\nSentence B: The earthquake caused a lot of damage to the city.\nSentence C: The earthquake destroyed many buildings in the city center.\nSentence D: The earthquake damaged many buildings in the city.\nSentence E: The earthquake caused a lot of damage.\nSentence F: Many people were scared during the recent earthquake.\n"
  },
  {
    "task_id": "B1_frighten",
    "level": "B1",
    "word": "frighten",
    "labeled_sentences": [
      [
        "Sentence A",
        "The loud noise will frighten the animals in the zoo."
      ],
      [
        "Sentence B",
        "He was frightened by the noise."
      ],
      [
        "Sentence C",
        "Loud noises often frighten small children and pets."
      ],
      [
        "Sentence D",
        "Thunder and lightning can frighten young children during storms."
      ],
      [
        "Sentence E",
        "Loud noises can easily frighten small children."
      ],
      [
        "Sentence F",
        "The loud noise will frighten the animals in the zoo."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "frighten",
        "sentence": "The loud noise will frighten the animals in the zoo."
      },
      "Sentence B": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "frighten",
        "sentence": "He was frightened by the noise."
      },
      "Sentence C": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "frighten",
        "sentence": "Loud noises often frighten small children and pets."
      },
      "Sentence D": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "frighten",
        "sentence": "Thunder and lightning can frighten young children during storms."
      },
      "Sentence E": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "frighten",
        "sentence": "Loud noises can easily frighten small children."
      },
      "Sentence F": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "frighten",
        "sentence": "The loud noise will frighten the animals in the zoo."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"frighten\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: The loud noise will frighten the animals in the zoo.\nSentence B: He was frightened by the noise.\nSentence C: Loud noises often frighten small children and pets.\nSentence D: Thunder and lightning can frighten young children during storms.\nSentence E: Loud noises can easily frighten small children.\nSentence F: The loud noise will frighten the animals in the zoo.\n"
  },
  {
    "task_id": "B1_issue",
    "level": "B1",
    "word": "issue",
    "labeled_sentences": [
      [
        "Sentence A",
        "There are many issues to discuss."
      ],
      [
        "Sentence B",
        "There is an issue with the water supply in our town, and we need to fix it."
      ],
      [
        "Sentence C",
        "Climate change is a serious issue we need to discuss."
      ],
      [
        "Sentence D",
        "We need to discuss this issue at tomorrow's meeting."
      ],
      [
        "Sentence E",
        "The issue of climate change is a serious problem."
      ],
      [
        "Sentence F",
        "We need to discuss this important issue at our next meeting."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "issue",
        "sentence": "There are many issues to discuss."
      },
      "Sentence B": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "issue",
        "sentence": "There is an issue with the water supply in our town, and we need to fix it."
      },
      "Sentence C": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "issue",
        "sentence": "Climate change is a serious issue we need to discuss."
      },
      "Sentence D": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "issue",
        "sentence": "We need to discuss this issue at tomorrow's meeting."
      },
      "Sentence E": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "issue",
        "sentence": "The issue of climate change is a serious problem."
      },
      "Sentence F": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "issue",
        "sentence": "We need to discuss this important issue at our next meeting."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"issue\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: There are many issues to discuss.\nSentence B: There is an issue with the water supply in our town, and we need to fix it.\nSentence C: Climate change is a serious issue we need to discuss.\nSentence D: We need to discuss this issue at tomorrow's meeting.\nSentence E: The issue of climate change is a serious problem.\nSentence F: We need to discuss this important issue at our next meeting.\n"
  },
  {
    "task_id": "B1_expand",
    "level": "B1",
    "word": "expand",
    "labeled_sentences": [
      [
        "Sentence A",
        "The company plans to expand its operations to other countries."
      ],
      [
        "Sentence B",
        "The company plans to expand its business into new countries next year."
      ],
      [
        "Sentence C",
        "The company plans to expand its business to other countries."
      ],
      [
        "Sentence D",
        "The company plans to expand its business to other countries."
      ],
      [
        "Sentence E",
        "The company plans to expand its business."
      ],
      [
        "Sentence F",
        "The company plans to expand into new markets next year."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "expand",
        "sentence": "The company plans to expand its operations to other countries."
      },
      "Sentence B": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "expand",
        "sentence": "The company plans to expand its business into new countries next year."
      },
      "Sentence C": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "expand",
        "sentence": "The company plans to expand its business to other countries."
      },
      "Sentence D": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "expand",
        "sentence": "The company plans to expand its business to other countries."
      },
      "Sentence E": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "expand",
        "sentence": "The company plans to expand its business."
      },
      "Sentence F": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "expand",
        "sentence": "The company plans to expand into new markets next year."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"expand\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: The company plans to expand its operations to other countries.\nSentence B: The company plans to expand its business into new countries next year.\nSentence C: The company plans to expand its business to other countries.\nSentence D: The company plans to expand its business to other countries.\nSentence E: The company plans to expand its business.\nSentence F: The company plans to expand into new markets next year.\n"
  },
  {
    "task_id": "B1_fancy",
    "level": "B1",
    "word": "fancy",
    "labeled_sentences": [
      [
        "Sentence A",
        "She has a fancy for flowers."
      ],
      [
        "Sentence B",
        "She wore a fancy dress to the wedding."
      ],
      [
        "Sentence C",
        "She has a fancy car that she bought last year."
      ],
      [
        "Sentence D",
        "She wore a fancy dress to the wedding celebration."
      ],
      [
        "Sentence E",
        "She wore a very fancy dress to the party."
      ],
      [
        "Sentence F",
        "She has a fancy handbag that she got for her birthday."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "fancy",
        "sentence": "She has a fancy for flowers."
      },
      "Sentence B": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "fancy",
        "sentence": "She wore a fancy dress to the wedding."
      },
      "Sentence C": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "fancy",
        "sentence": "She has a fancy car that she bought last year."
      },
      "Sentence D": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "fancy",
        "sentence": "She wore a fancy dress to the wedding celebration."
      },
      "Sentence E": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "fancy",
        "sentence": "She wore a very fancy dress to the party."
      },
      "Sentence F": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "fancy",
        "sentence": "She has a fancy handbag that she got for her birthday."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"fancy\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: She has a fancy for flowers.\nSentence B: She wore a fancy dress to the wedding.\nSentence C: She has a fancy car that she bought last year.\nSentence D: She wore a fancy dress to the wedding celebration.\nSentence E: She wore a very fancy dress to the party.\nSentence F: She has a fancy handbag that she got for her birthday.\n"
  },
  {
    "task_id": "B1_imaginary",
    "level": "B1",
    "word": "imaginary",
    "labeled_sentences": [
      [
        "Sentence A",
        "The imaginary world of the story was fascinating."
      ],
      [
        "Sentence B",
        "The imaginary world in the book is very interesting."
      ],
      [
        "Sentence C",
        "Unicorns are imaginary animals, not real ones."
      ],
      [
        "Sentence D",
        "As a child, he had an imaginary friend."
      ],
      [
        "Sentence E",
        "The children created an imaginary friend to play with."
      ],
      [
        "Sentence F",
        "The story was so imaginary that I couldn't distinguish reality from fantasy."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "imaginary",
        "sentence": "The imaginary world of the story was fascinating."
      },
      "Sentence B": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "imaginary",
        "sentence": "The imaginary world in the book is very interesting."
      },
      "Sentence C": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "imaginary",
        "sentence": "Unicorns are imaginary animals, not real ones."
      },
      "Sentence D": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "imaginary",
        "sentence": "As a child, he had an imaginary friend."
      },
      "Sentence E": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "imaginary",
        "sentence": "The children created an imaginary friend to play with."
      },
      "Sentence F": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "imaginary",
        "sentence": "The story was so imaginary that I couldn't distinguish reality from fantasy."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"imaginary\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: The imaginary world of the story was fascinating.\nSentence B: The imaginary world in the book is very interesting.\nSentence C: Unicorns are imaginary animals, not real ones.\nSentence D: As a child, he had an imaginary friend.\nSentence E: The children created an imaginary friend to play with.\nSentence F: The story was so imaginary that I couldn't distinguish reality from fantasy.\n"
  },
  {
    "task_id": "B1_poet",
    "level": "B1",
    "word": "poet",
    "labeled_sentences": [
      [
        "Sentence A",
        "William Shakespeare was a famous English poet."
      ],
      [
        "Sentence B",
        "The poet's latest collection of poems is a bestseller."
      ],
      [
        "Sentence C",
        "The poet wrote beautiful verses about love and nature."
      ],
      [
        "Sentence D",
        "The poet wrote about love."
      ],
      [
        "Sentence E",
        "Shakespeare was a famous poet who wrote beautiful sonnets."
      ],
      [
        "Sentence F",
        "William Shakespeare was a famous English poet."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "poet",
        "sentence": "William Shakespeare was a famous English poet."
      },
      "Sentence B": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "poet",
        "sentence": "The poet's latest collection of poems is a bestseller."
      },
      "Sentence C": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "poet",
        "sentence": "The poet wrote beautiful verses about love and nature."
      },
      "Sentence D": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "poet",
        "sentence": "The poet wrote about love."
      },
      "Sentence E": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "poet",
        "sentence": "Shakespeare was a famous poet who wrote beautiful sonnets."
      },
      "Sentence F": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "poet",
        "sentence": "William Shakespeare was a famous English poet."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"poet\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: William Shakespeare was a famous English poet.\nSentence B: The poet's latest collection of poems is a bestseller.\nSentence C: The poet wrote beautiful verses about love and nature.\nSentence D: The poet wrote about love.\nSentence E: Shakespeare was a famous poet who wrote beautiful sonnets.\nSentence F: William Shakespeare was a famous English poet.\n"
  },
  {
    "task_id": "B1_religion",
    "level": "B1",
    "word": "religion",
    "labeled_sentences": [
      [
        "Sentence A",
        "Different cultures have their own religion and traditions."
      ],
      [
        "Sentence B",
        "People should respect each other's religion."
      ],
      [
        "Sentence C",
        "The new employee has to respect the company's religion policy."
      ],
      [
        "Sentence D",
        "Her religion is important to her."
      ],
      [
        "Sentence E",
        "Different cultures practice different forms of religion."
      ],
      [
        "Sentence F",
        "The religion of Buddhism emphasizes the importance of meditation and compassion."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "religion",
        "sentence": "Different cultures have their own religion and traditions."
      },
      "Sentence B": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "religion",
        "sentence": "People should respect each other's religion."
      },
      "Sentence C": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "religion",
        "sentence": "The new employee has to respect the company's religion policy."
      },
      "Sentence D": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "religion",
        "sentence": "Her religion is important to her."
      },
      "Sentence E": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "religion",
        "sentence": "Different cultures practice different forms of religion."
      },
      "Sentence F": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "religion",
        "sentence": "The religion of Buddhism emphasizes the importance of meditation and compassion."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"religion\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: Different cultures have their own religion and traditions.\nSentence B: People should respect each other's religion.\nSentence C: The new employee has to respect the company's religion policy.\nSentence D: Her religion is important to her.\nSentence E: Different cultures practice different forms of religion.\nSentence F: The religion of Buddhism emphasizes the importance of meditation and compassion.\n"
  },
  {
    "task_id": "B1_obvious",
    "level": "B1",
    "word": "obvious",
    "labeled_sentences": [
      [
        "Sentence A",
        "It’s obvious that he didn’t study for the exam."
      ],
      [
        "Sentence B",
        "It was obvious that he hadn't studied for the test."
      ],
      [
        "Sentence C",
        "The obvious solution was to call the police."
      ],
      [
        "Sentence D",
        "It's obvious that she's not interested in the conversation, so let's move on."
      ],
      [
        "Sentence E",
        "It was obvious that he was tired because he kept yawning."
      ],
      [
        "Sentence F",
        "It's obvious that the new policy will have a negative impact."
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "obvious",
        "sentence": "It’s obvious that he didn’t study for the exam."
      },
      "Sentence B": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "obvious",
        "sentence": "It was obvious that he hadn't studied for the test."
      },
      "Sentence C": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "obvious",
        "sentence": "The obvious solution was to call the police."
      },
      "Sentence D": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "obvious",
        "sentence": "It's obvious that she's not interested in the conversation, so let's move on."
      },
      "Sentence E": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "obvious",
        "sentence": "It was obvious that he was tired because he kept yawning."
      },
      "Sentence F": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "obvious",
        "sentence": "It's obvious that the new policy will have a negative impact."
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"obvious\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: It’s obvious that he didn’t study for the exam.\nSentence B: It was obvious that he hadn't studied for the test.\nSentence C: The obvious solution was to call the police.\nSentence D: It's obvious that she's not interested in the conversation, so let's move on.\nSentence E: It was obvious that he was tired because he kept yawning.\nSentence F: It's obvious that the new policy will have a negative impact.\n"
  },
  {
    "task_id": "B1_sort",
    "level": "B1",
    "word": "sort",
    "labeled_sentences": [
      [
        "Sentence A",
        "We need to sort the files on our computer to make it easier to find them."
      ],
      [
        "Sentence B",
        "Let’s sort these books by size and color."
      ],
      [
        "Sentence C",
        "I sorted the books by author."
      ],
      [
        "Sentence D",
        "Can you sort out the papers on my desk and file them away?"
      ],
      [
        "Sentence E",
        "Can you help me to sort these books by author?"
      ],
      [
        "Sentence F",
        "What sort of music do you prefer listening to?"
      ]
    ],
    "mapping": {
      "Sentence A": {
        "model": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "sort",
        "sentence": "We need to sort the files on our computer to make it easier to find them."
      },
      "Sentence B": {
        "model": "GPT-4-turbo",
        "level": "B1",
        "word": "sort",
        "sentence": "Let’s sort these books by size and color."
      },
      "Sentence C": {
        "model": "Ministral-8B-Instruct-2410.Q4_K_M.gguf",
        "level": "B1",
        "word": "sort",
        "sentence": "I sorted the books by author."
      },
      "Sentence D": {
        "model": "Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf",
        "level": "B1",
        "word": "sort",
        "sentence": "Can you sort out the papers on my desk and file them away?"
      },
      "Sentence E": {
        "model": "Gemini 2.5 Flash",
        "level": "B1",
        "word": "sort",
        "sentence": "Can you help me to sort these books by author?"
      },
      "Sentence F": {
        "model": "Claude Sonnet 4",
        "level": "B1",
        "word": "sort",
        "sentence": "What sort of music do you prefer listening to?"
      }
    },
    "prompt": "You are a professional CEFR-aligned English sentence evaluator.\n\nYour task is to evaluate 6 example sentences that all use the target word: \"sort\" at CEFR level: B1.\n\nRate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n\n1. **Word Usage** – Is the target word used correctly and meaningfully in context?\n2. **Clarity** – Is the sentence understandable and suitable for the given CEFR level?\n3. **Grammar** – Is the grammar accurate and appropriate for the level?\n4. **Naturalness** – Does the sentence sound fluent and natural to a native speaker?\n\n⚠️ Important Instructions:\n- **Only return numerical ratings** for each criterion.\n- **Do not include any explanations, comments, or justifications.**\n- Follow the exact output format below.\n\n### Output Format:\nSentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \nSentence B: ...  \nSentence C: ...  \nSentence D: ...  \nSentence E: ...  \nSentence F: ...  \n\n### Sentences:\nSentence A: We need to sort the files on our computer to make it easier to find them.\nSentence B: Let’s sort these books by size and color.\nSentence C: I sorted the books by author.\nSentence D: Can you sort out the papers on my desk and file them away?\nSentence E: Can you help me to sort these books by author?\nSentence F: What sort of music do you prefer listening to?\n"
  }
]