# A1 Seviyesi - Model Performans Analizi Raporu
**Analiz Tarihi:** 27.10.2025 16:37
**Toplam Katılımcı Sayısı:** 16
**Toplam Değerlendirme Sayısı:** 3840
**Değerlendirilen Kelime Sayısı:** 10

---

## 1. Genel Model Sıralaması

| Sıra | Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|------|-------|---------------|------------|---------------------|
| 1 | Claude_Sonnet_4.5 | 4.098 | ±0.940 | 640 |
| 2 | Gemini_Pro_2.5 | 3.889 | ±1.065 | 640 |
| 3 | mistralai_Ministral-8B-Instruct-2410 | 3.881 | ±1.086 | 640 |
| 4 | Llama-3.2-1B-Instruct-FineTuned | 3.844 | ±1.081 | 640 |
| 5 | Llama-3.1-8B-Instruct | 3.831 | ±1.037 | 640 |
| 6 | Llama-3.2-1B-Instruct | 3.639 | ±1.200 | 640 |

## 2. Kriter Bazında Model Performansı

### 2.1. Kelime Kullanımı (Word Usage)

| Sıra | Model | Ortalama Puan | Std. Sapma |
|------|-------|---------------|------------|
| 1 | Claude_Sonnet_4.5 | 4.131 | ±0.870 |
| 2 | Llama-3.2-1B-Instruct-FineTuned | 3.906 | ±0.989 |
| 3 | mistralai_Ministral-8B-Instruct-2410 | 3.906 | ±1.057 |
| 4 | Gemini_Pro_2.5 | 3.862 | ±1.049 |
| 5 | Llama-3.1-8B-Instruct | 3.862 | ±1.012 |
| 6 | Llama-3.2-1B-Instruct | 3.675 | ±1.169 |

### 2.2. Seviye Uygunluğu (Level Appropriateness)

| Sıra | Model | Ortalama Puan | Std. Sapma |
|------|-------|---------------|------------|
| 1 | Claude_Sonnet_4.5 | 4.144 | ±0.889 |
| 2 | Gemini_Pro_2.5 | 4.012 | ±0.990 |
| 3 | mistralai_Ministral-8B-Instruct-2410 | 4.000 | ±1.003 |
| 4 | Llama-3.1-8B-Instruct | 3.912 | ±0.974 |
| 5 | Llama-3.2-1B-Instruct-FineTuned | 3.881 | ±1.042 |
| 6 | Llama-3.2-1B-Instruct | 3.675 | ±1.163 |

### 2.3. Dilbilgisi Doğruluğu (Grammatical Accuracy)

| Sıra | Model | Ortalama Puan | Std. Sapma |
|------|-------|---------------|------------|
| 1 | Claude_Sonnet_4.5 | 4.075 | ±0.968 |
| 2 | Gemini_Pro_2.5 | 3.831 | ±1.123 |
| 3 | mistralai_Ministral-8B-Instruct-2410 | 3.800 | ±1.137 |
| 4 | Llama-3.2-1B-Instruct-FineTuned | 3.762 | ±1.190 |
| 5 | Llama-3.1-8B-Instruct | 3.731 | ±1.126 |
| 6 | Llama-3.2-1B-Instruct | 3.594 | ±1.235 |

### 2.4. Doğallık (Naturalness)

| Sıra | Model | Ortalama Puan | Std. Sapma |
|------|-------|---------------|------------|
| 1 | Claude_Sonnet_4.5 | 4.044 | ±1.030 |
| 2 | Gemini_Pro_2.5 | 3.850 | ±1.094 |
| 3 | Llama-3.2-1B-Instruct-FineTuned | 3.825 | ±1.096 |
| 4 | Llama-3.1-8B-Instruct | 3.819 | ±1.033 |
| 5 | mistralai_Ministral-8B-Instruct-2410 | 3.819 | ±1.138 |
| 6 | Llama-3.2-1B-Instruct | 3.612 | ±1.239 |

## 3. Kelime Bazında Model Performansı

### air

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| mistralai_Ministral-8B-Instruct-2410 | 3.969 | ±0.835 | 64 |
| Claude_Sonnet_4.5 | 3.906 | ±0.868 | 64 |
| Llama-3.1-8B-Instruct | 3.719 | ±0.863 | 64 |
| Gemini_Pro_2.5 | 3.375 | ±1.134 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 3.234 | ±1.004 | 64 |
| Llama-3.2-1B-Instruct | 2.328 | ±1.235 | 64 |

### amazing

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| Claude_Sonnet_4.5 | 4.281 | ±1.000 | 64 |
| Llama-3.2-1B-Instruct | 4.203 | ±0.876 | 64 |
| Gemini_Pro_2.5 | 4.094 | ±0.988 | 64 |
| Llama-3.1-8B-Instruct | 4.078 | ±0.878 | 64 |
| mistralai_Ministral-8B-Instruct-2410 | 4.031 | ±1.007 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 3.953 | ±1.075 | 64 |

### animal

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| Claude_Sonnet_4.5 | 4.203 | ±0.800 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 4.062 | ±1.022 | 64 |
| Llama-3.1-8B-Instruct | 3.750 | ±1.260 | 64 |
| Gemini_Pro_2.5 | 3.547 | ±1.181 | 64 |
| Llama-3.2-1B-Instruct | 3.297 | ±1.150 | 64 |
| mistralai_Ministral-8B-Instruct-2410 | 2.875 | ±1.162 | 64 |

### ask

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| Claude_Sonnet_4.5 | 4.234 | ±1.004 | 64 |
| Llama-3.1-8B-Instruct | 4.203 | ±0.760 | 64 |
| Gemini_Pro_2.5 | 4.031 | ±0.890 | 64 |
| Llama-3.2-1B-Instruct | 3.875 | ±0.882 | 64 |
| mistralai_Ministral-8B-Instruct-2410 | 3.594 | ±1.244 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 3.078 | ±1.251 | 64 |

### but

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| Claude_Sonnet_4.5 | 4.094 | ±1.003 | 64 |
| mistralai_Ministral-8B-Instruct-2410 | 4.016 | ±1.046 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 3.938 | ±1.167 | 64 |
| Gemini_Pro_2.5 | 3.875 | ±1.062 | 64 |
| Llama-3.1-8B-Instruct | 3.875 | ±1.031 | 64 |
| Llama-3.2-1B-Instruct | 3.766 | ±1.123 | 64 |

### car

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| Llama-3.2-1B-Instruct-FineTuned | 4.438 | ±0.774 | 64 |
| Gemini_Pro_2.5 | 4.375 | ±0.745 | 64 |
| mistralai_Ministral-8B-Instruct-2410 | 4.172 | ±1.001 | 64 |
| Claude_Sonnet_4.5 | 4.078 | ±1.044 | 64 |
| Llama-3.1-8B-Instruct | 3.719 | ±0.983 | 64 |
| Llama-3.2-1B-Instruct | 3.500 | ±1.141 | 64 |

### computer

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| Claude_Sonnet_4.5 | 4.281 | ±0.806 | 64 |
| mistralai_Ministral-8B-Instruct-2410 | 4.203 | ±0.876 | 64 |
| Llama-3.2-1B-Instruct | 4.188 | ±0.924 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 3.984 | ±0.766 | 64 |
| Llama-3.1-8B-Instruct | 3.875 | ±0.934 | 64 |
| Gemini_Pro_2.5 | 3.641 | ±1.029 | 64 |

### drive

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| mistralai_Ministral-8B-Instruct-2410 | 4.344 | ±0.781 | 64 |
| Claude_Sonnet_4.5 | 4.297 | ±0.770 | 64 |
| Gemini_Pro_2.5 | 4.172 | ±0.808 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 3.844 | ±0.979 | 64 |
| Llama-3.2-1B-Instruct | 3.609 | ±1.217 | 64 |
| Llama-3.1-8B-Instruct | 3.594 | ±1.281 | 64 |

### eat

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| Llama-3.2-1B-Instruct | 4.234 | ±0.750 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 4.172 | ±0.865 | 64 |
| Gemini_Pro_2.5 | 4.062 | ±0.889 | 64 |
| Claude_Sonnet_4.5 | 3.891 | ±0.928 | 64 |
| Llama-3.1-8B-Instruct | 3.781 | ±1.046 | 64 |
| mistralai_Ministral-8B-Instruct-2410 | 3.562 | ±1.153 | 64 |

### funny

| Model | Ortalama Puan | Std. Sapma | Değerlendirme Sayısı |
|-------|---------------|------------|---------------------|
| mistralai_Ministral-8B-Instruct-2410 | 4.047 | ±0.916 | 64 |
| Llama-3.2-1B-Instruct-FineTuned | 3.734 | ±1.130 | 64 |
| Claude_Sonnet_4.5 | 3.719 | ±1.000 | 64 |
| Gemini_Pro_2.5 | 3.719 | ±1.408 | 64 |
| Llama-3.1-8B-Instruct | 3.719 | ±1.133 | 64 |
| Llama-3.2-1B-Instruct | 3.391 | ±1.317 | 64 |

## 4. İstatistiksel Özet

- **En Yüksek Ortalama Puan:** 4.098 (Claude_Sonnet_4.5)
- **En Düşük Ortalama Puan:** 3.639 (Llama-3.2-1B-Instruct)
- **Ortalama Puan Aralığı:** 0.459
- **Genel Ortalama:** 3.864
- **Genel Standart Sapma:** 0.147

## 5. Önemli Gözlemler

### 5.1. En İyi Performans
**Claude_Sonnet_4.5** modeli 4.098 ortalama puan ile en iyi performansı göstermiştir.

### 5.2. En Düşük Performans
**Llama-3.2-1B-Instruct** modeli 3.639 ortalama puan ile en düşük performansı göstermiştir.

### 5.3. Kriter Bazında En İyi Modeller

- **Kelime Kullanımı:** Claude_Sonnet_4.5 (4.131)
- **Seviye Uygunluğu:** Claude_Sonnet_4.5 (4.144)
- **Dilbilgisi Doğruluğu:** Claude_Sonnet_4.5 (4.075)
- **Doğallık:** Claude_Sonnet_4.5 (4.044)

## 6. Sonuç

Bu analizde 16 katılımcıdan toplanan 3840 değerlendirme üzerinden 6 farklı modelin A1 seviyesi cümle üretme performansı incelenmiştir.

**Temel Bulgular:**
1. Claude Sonnet 4.5 modeli genel olarak en yüksek performansı göstermiştir (Ortalama: 4.098)
2. Tüm modellerin ortalama puanı 3.864 olarak hesaplanmıştır
3. Modeller arası performans farkı 0.459 puan olarak ölçülmüştür

---

*Bu rapor otomatik olarak oluşturulmuştur.*
