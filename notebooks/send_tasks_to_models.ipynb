{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b6f232",
   "metadata": {},
   "source": [
    "# DeepSeek-Chat Modele Prompt GÃ¶nderip SonuÃ§ Almak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72f6a6-fdbd-48a8-8e82-f9df315d8187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================  START A2  ================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing A2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:24<00:00, 14.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… A2: 60 satÄ±r kaydedildi â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/deepseek_ratings/ratings_A2.json\n",
      "\n",
      "================================  START B1  ================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing B1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:19<00:00, 13.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… B1: 60 satÄ±r kaydedildi â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/deepseek_ratings/ratings_B1.json\n",
      "\n",
      "================================  START B2  ================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing B2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:29<00:00, 14.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… B2: 60 satÄ±r kaydedildi â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/deepseek_ratings/ratings_B2.json\n",
      "\n",
      "================================  START C1  ================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing C1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:20<00:00, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… C1: 60 satÄ±r kaydedildi â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/deepseek_ratings/ratings_C1.json\n",
      "\n",
      "ðŸŽ‰ Bitti: A2â†’C1 deÄŸerlendirmeleri yazÄ±ldÄ±.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# --- Ortam deÄŸiÅŸkenlerini yÃ¼kle ---\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# --- Sabitler / Ayarlar ---\n",
    "LEVELS = [\"A2\", \"B1\", \"B2\", \"C1\"]  # A1'i zaten Ã¼rettin\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "TEMPERATURE = 1.0                  # 0.0-1.0 arasÄ± deÄŸer, 1.0 daha yaratÄ±cÄ± sonuÃ§lar verir\n",
    "N_EVALS = 2                        # her task iÃ§in kaÃ§ tekrar\n",
    "\n",
    "API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"DEEPSEEK_API_KEY ortam deÄŸiÅŸkeni tanÄ±mlÄ± deÄŸil!\")\n",
    "\n",
    "# --- Ä°stemci ---\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "# --- Yollar ---\n",
    "root = os.getcwd()\n",
    "tasks_dir = os.path.abspath(os.path.join(root, \"..\", \"data\", \"tasks\"))\n",
    "ratings_root = os.path.abspath(os.path.join(root, \"..\", \"data\", \"ratings\"))\n",
    "output_dir = os.path.join(ratings_root, \"deepseek_ratings\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- AyrÄ±ÅŸtÄ±rma ---\n",
    "def parse_response(response_text: str) -> Dict[str, Dict[str, int]]:\n",
    "    pattern = r\"Sentence\\s*([A-F])\\s*:\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\"\n",
    "    results = {}\n",
    "    for m in re.finditer(pattern, response_text):\n",
    "        label = f\"Sentence {m.group(1)}\"\n",
    "        s = list(map(int, m.groups()[1:]))\n",
    "        results[label] = {\"word_usage\": s[0], \"clarity\": s[1], \"grammar\": s[2], \"naturalness\": s[3]}\n",
    "    return results\n",
    "\n",
    "# --- GÃ¼venli Ã§aÄŸrÄ± ---\n",
    "def call_deepseek(prompt: str, retries: int = 3, backoff: float = 2.0) -> str:\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=TEMPERATURE,\n",
    "                stream=False,\n",
    "            )\n",
    "            return resp.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] API Ã§aÄŸrÄ±sÄ± baÅŸarÄ±sÄ±z (deneme {attempt}/{retries}): {e}\")\n",
    "            if attempt < retries:\n",
    "                time.sleep(backoff ** attempt)\n",
    "            else:\n",
    "                raise\n",
    "    return \"\"\n",
    "\n",
    "def average_scores(score_dicts: List[Dict[str, Dict[str, int]]]) -> Dict[str, Dict[str, float]]:\n",
    "    merged: Dict[str, Dict[str, List[float]]] = {}\n",
    "    for sd in score_dicts:\n",
    "        for label, metrics in sd.items():\n",
    "            merged.setdefault(label, {k: [] for k in [\"word_usage\",\"clarity\",\"grammar\",\"naturalness\"]})\n",
    "            for k, v in metrics.items():\n",
    "                if isinstance(v, (int, float)):\n",
    "                    merged[label][k].append(float(v))\n",
    "    averaged: Dict[str, Dict[str, float]] = {}\n",
    "    for label, lists in merged.items():\n",
    "        averaged[label] = {k: (sum(vals)/len(vals) if vals else 0.0) for k, vals in lists.items()}\n",
    "    return averaged\n",
    "\n",
    "def process_level(level: str):\n",
    "    tasks_path = os.path.join(tasks_dir, f\"tasks_{level}.json\")\n",
    "    out_path   = os.path.join(output_dir, f\"ratings_{level}.json\")\n",
    "\n",
    "    if not os.path.exists(tasks_path):\n",
    "        print(f\"[ATLA] Task dosyasÄ± yok: {tasks_path}\")\n",
    "        return\n",
    "\n",
    "    with open(tasks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tasks = json.load(f)\n",
    "\n",
    "    all_ratings = []\n",
    "    for task in tqdm(tasks, desc=f\"Processing {level}\"):\n",
    "        prompt  = task[\"prompt\"]\n",
    "        mapping = task[\"mapping\"]\n",
    "        task_id = task[\"task_id\"]\n",
    "        word    = task[\"word\"]\n",
    "\n",
    "        try:\n",
    "            runs = []\n",
    "            for _ in range(N_EVALS):\n",
    "                reply = call_deepseek(prompt)\n",
    "                runs.append(parse_response(reply))\n",
    "\n",
    "            averaged = average_scores(runs)\n",
    "\n",
    "            for label, rating in averaged.items():\n",
    "                if label not in mapping:\n",
    "                    print(f\"[UYARI] EÅŸleÅŸmeyen etiket: {label} (task_id={task_id})\"); continue\n",
    "                all_ratings.append({\n",
    "                    \"task_id\":  task_id,\n",
    "                    \"model\":    mapping[label][\"model\"],\n",
    "                    \"level\":    level,\n",
    "                    \"word\":     word,\n",
    "                    \"label\":    label,\n",
    "                    \"sentence\": mapping[label][\"sentence\"],\n",
    "                    \"ratings\":  {\n",
    "                        \"word_usage\": round(rating.get(\"word_usage\", 0.0), 3),\n",
    "                        \"clarity\":     round(rating.get(\"clarity\", 0.0), 3),\n",
    "                        \"grammar\":     round(rating.get(\"grammar\", 0.0), 3),\n",
    "                        \"naturalness\": round(rating.get(\"naturalness\", 0.0), 3),\n",
    "                    }\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] Level={level} Task={task_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_ratings, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ… {level}: {len(all_ratings)} satÄ±r kaydedildi â†’ {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for lvl in LEVELS:\n",
    "        print(\"\\n\" + \"=\"*32 + f\"  START {lvl}  \" + \"=\"*32)\n",
    "        process_level(lvl)\n",
    "    print(\"\\nðŸŽ‰ Bitti: A2â†’C1 deÄŸerlendirmeleri yazÄ±ldÄ±.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b731a50",
   "metadata": {},
   "source": [
    "# deepseek-reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f7ae9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== deepseek-reasoner deÄŸerlendirmesi: A1â†’C1 ===\n",
      "\n",
      "========================  START A1  ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing A1 (reasoner):   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HATA] API Ã§aÄŸrÄ±sÄ± baÅŸarÄ±sÄ±z (deneme 1/3): <!DOCTYPE html>\n",
      "<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\n",
      "<head>\n",
      "\n",
      "\n",
      "<title>api.deepseek.com | 504: Gateway time-out</title>\n",
      "<meta charset=\"UTF-8\" />\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\" />\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"cf-wrapper\">\n",
      "    <div id=\"cf-error-details\" class=\"p-0\">\n",
      "        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\n",
      "            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\n",
      "              <span class=\"inline-block\">Gateway time-out</span>\n",
      "              <span class=\"code-label\">Error code 504</span>\n",
      "            </h1>\n",
      "            <div>\n",
      "               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.deepseek.com\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\n",
      "            </div>\n",
      "            <div class=\"mt-3\">2025-08-11 13:52:02 UTC</div>\n",
      "        </header>\n",
      "        <div class=\"my-8 bg-gradient-gray\">\n",
      "            <div class=\"w-240 lg:w-full mx-auto\">\n",
      "                <div class=\"clearfix md:px-8\">\n",
      "                  \n",
      "<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">You</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Browser\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.deepseek.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    </a>\n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">Istanbul</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.deepseek.com\" target=\"_blank\" rel=\"noopener noreferrer\">\n",
      "    Cloudflare\n",
      "    </a>\n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\n",
      "</div>\n",
      "\n",
      "<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\n",
      "  <div class=\"relative mb-10 md:m-0\">\n",
      "    \n",
      "    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\n",
      "    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\n",
      "    \n",
      "  </div>\n",
      "  <span class=\"md:block w-full truncate\">api.deepseek.com</span>\n",
      "  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\n",
      "    \n",
      "    Host\n",
      "    \n",
      "  </h3>\n",
      "  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\n",
      "</div>\n",
      "\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\n",
      "            <div class=\"clearfix\">\n",
      "                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\n",
      "                    <p>The web server reported a gateway time-out error.</p>\n",
      "                </div>\n",
      "                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\n",
      "                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\n",
      "                    <p class=\"mb-6\">Please try again in a few minutes.</p>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\n",
      "  <p class=\"text-13\">\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">96d82eb998b6c530</strong></span>\n",
      "    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\n",
      "      Your IP:\n",
      "      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\n",
      "      <span class=\"hidden\" id=\"cf-footer-ip\">88.255.218.254</span>\n",
      "      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\n",
      "    </span>\n",
      "    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_504&utm_campaign=api.deepseek.com\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\n",
      "    \n",
      "  </p>\n",
      "  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\n",
      "</div><!-- /.error-footer -->\n",
      "\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing A1 (reasoner):   0%|          | 0/10 [15:35<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 155\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lvl \u001b[38;5;129;01min\u001b[39;00m LEVELS:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m24\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  START \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlvl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m24\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[43mprocess_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸŽ‰ Bitti: SonuÃ§lar data/ratings/deepseek_ratings/ altÄ±nda ratings_reasoner_\u001b[39m\u001b[38;5;132;01m{LEVEL}\u001b[39;00m\u001b[33m.json dosyalarÄ±na yazÄ±ldÄ±.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mprocess_level\u001b[39m\u001b[34m(level)\u001b[39m\n\u001b[32m    106\u001b[39m runs = []\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m run_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EVALS):\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     reply = \u001b[43mcall_deepseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m RAW_LOG:\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(raw_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m__run\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_idx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m__prompt.txt\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pf:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mcall_deepseek\u001b[39m\u001b[34m(prompt, retries, backoff)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, retries + \u001b[32m1\u001b[39m):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m resp.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1131\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1086\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1088\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1128\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1129\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1130\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/openai/_base_client.py:1256\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1244\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1251\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1252\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1253\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1254\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1255\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/openai/_base_client.py:979\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    977\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    985\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Tez/Deneyler/LLM_Degerlendirme/venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# --- ENV ---\n",
    "load_dotenv(find_dotenv())\n",
    "API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"DEEPSEEK_API_KEY ortam deÄŸiÅŸkeni tanÄ±mlÄ± deÄŸil!\")\n",
    "\n",
    "# --- Ayarlar ---\n",
    "LEVELS = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\"]\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL_NAME = \"deepseek-reasoner\"   # <<<< reasoner modeli\n",
    "TEMPERATURE = 1.0                  # 0.0-1.0 arasÄ±; 1.0 daha yaratÄ±cÄ±\n",
    "N_EVALS = 2                        # her task iÃ§in kaÃ§ tekrar (ortalama alÄ±nÄ±r)\n",
    "\n",
    "# --- Ä°stemci ---\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "# --- Yollar ---\n",
    "root = os.getcwd()\n",
    "tasks_dir = os.path.abspath(os.path.join(root, \"..\", \"data\", \"tasks\"))\n",
    "ratings_root = os.path.abspath(os.path.join(root, \"..\", \"data\", \"ratings\"))\n",
    "output_dir = os.path.join(ratings_root, \"deepseek_ratings\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# (Opsiyonel) ham loglar\n",
    "RAW_LOG = False\n",
    "raw_dir = os.path.join(output_dir, \"reasoner_raw_logs\")\n",
    "if RAW_LOG:\n",
    "    os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "# --- AyrÄ±ÅŸtÄ±rma ---\n",
    "def parse_response(response_text: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Format Ã¶rneÄŸi:\n",
    "      Sentence A: 4, 4, 5, 4\n",
    "      ...\n",
    "    DÃ¶nÃ¼ÅŸ: {\"Sentence A\": {\"word_usage\":int, \"clarity\":int, \"grammar\":int, \"naturalness\":int}, ...}\n",
    "    \"\"\"\n",
    "    pattern = r\"Sentence\\s*([A-F])\\s*:\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\"\n",
    "    results = {}\n",
    "    for m in re.finditer(pattern, response_text):\n",
    "        label = f\"Sentence {m.group(1)}\"\n",
    "        s = list(map(int, m.groups()[1:]))\n",
    "        results[label] = {\"word_usage\": s[0], \"clarity\": s[1], \"grammar\": s[2], \"naturalness\": s[3]}\n",
    "    return results\n",
    "\n",
    "def average_scores(score_dicts: List[Dict[str, Dict[str, int]]]) -> Dict[str, Dict[str, float]]:\n",
    "    merged: Dict[str, Dict[str, List[float]]] = {}\n",
    "    for sd in score_dicts:\n",
    "        for label, metrics in sd.items():\n",
    "            merged.setdefault(label, {k: [] for k in [\"word_usage\",\"clarity\",\"grammar\",\"naturalness\"]})\n",
    "            for k, v in metrics.items():\n",
    "                if isinstance(v, (int, float)):\n",
    "                    merged[label][k].append(float(v))\n",
    "    averaged: Dict[str, Dict[str, float]] = {}\n",
    "    for label, lists in merged.items():\n",
    "        averaged[label] = {k: (sum(vals)/len(vals) if vals else 0.0) for k, vals in lists.items()}\n",
    "    return averaged\n",
    "\n",
    "# --- API Ã§aÄŸrÄ±sÄ± (retry/backoff) ---\n",
    "def call_deepseek(prompt: str, retries: int = 3, backoff: float = 2.0) -> str:\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=TEMPERATURE,\n",
    "                stream=False,\n",
    "            )\n",
    "            return resp.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] API Ã§aÄŸrÄ±sÄ± baÅŸarÄ±sÄ±z (deneme {attempt}/{retries}): {e}\")\n",
    "            if attempt < retries:\n",
    "                time.sleep(backoff ** attempt)\n",
    "            else:\n",
    "                raise\n",
    "    return \"\"\n",
    "\n",
    "def process_level(level: str):\n",
    "    tasks_path = os.path.join(tasks_dir, f\"tasks_{level}.json\")\n",
    "    out_path   = os.path.join(output_dir, f\"ratings_reasoner_{level}.json\")  # <<<< ayrÄ± dosya adÄ±\n",
    "\n",
    "    if not os.path.exists(tasks_path):\n",
    "        print(f\"[ATLA] Task dosyasÄ± yok: {tasks_path}\")\n",
    "        return\n",
    "\n",
    "    with open(tasks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tasks = json.load(f)\n",
    "\n",
    "    all_ratings = []\n",
    "    for task in tqdm(tasks, desc=f\"Processing {level} (reasoner)\"):\n",
    "        prompt  = task[\"prompt\"]\n",
    "        mapping = task[\"mapping\"]\n",
    "        task_id = task[\"task_id\"]\n",
    "        word    = task[\"word\"]\n",
    "\n",
    "        try:\n",
    "            runs = []\n",
    "            for run_idx in range(N_EVALS):\n",
    "                reply = call_deepseek(prompt)\n",
    "                if RAW_LOG:\n",
    "                    with open(os.path.join(raw_dir, f\"{level}__{task_id}__run{run_idx+1}__prompt.txt\"), \"w\", encoding=\"utf-8\") as pf:\n",
    "                        pf.write(prompt)\n",
    "                    with open(os.path.join(raw_dir, f\"{level}__{task_id}__run{run_idx+1}__reply.txt\"), \"w\", encoding=\"utf-8\") as rf:\n",
    "                        rf.write(reply)\n",
    "                runs.append(parse_response(reply))\n",
    "\n",
    "            averaged = average_scores(runs)\n",
    "\n",
    "            for label, rating in averaged.items():\n",
    "                if label not in mapping:\n",
    "                    print(f\"[UYARI] EÅŸleÅŸmeyen etiket: {label} (task_id={task_id})\")\n",
    "                    continue\n",
    "\n",
    "                all_ratings.append({\n",
    "                    \"task_id\":  task_id,\n",
    "                    \"model\":    mapping[label][\"model\"],\n",
    "                    \"level\":    level,\n",
    "                    \"word\":     word,\n",
    "                    \"label\":    label,\n",
    "                    \"sentence\": mapping[label][\"sentence\"],\n",
    "                    \"ratings\":  {\n",
    "                        \"word_usage\": round(rating.get(\"word_usage\", 0.0), 3),\n",
    "                        \"clarity\":     round(rating.get(\"clarity\", 0.0), 3),\n",
    "                        \"grammar\":     round(rating.get(\"grammar\", 0.0), 3),\n",
    "                        \"naturalness\": round(rating.get(\"naturalness\", 0.0), 3),\n",
    "                    }\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] Level={level} Task={task_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_ratings, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    task_ids = {r[\"task_id\"] for r in all_ratings}\n",
    "    expected_rows = 6 * len(task_ids)\n",
    "    print(f\"âœ… {level} (reasoner): {len(all_ratings)} satÄ±r kaydedildi â†’ {out_path}\")\n",
    "    if len(all_ratings) != expected_rows:\n",
    "        print(f\"âš ï¸  {level}: SatÄ±r sayÄ±sÄ± beklenenle uyuÅŸmuyor (beklenen {expected_rows}, gerÃ§ek {len(all_ratings)}).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n=== deepseek-reasoner deÄŸerlendirmesi: A1â†’C1 ===\")\n",
    "    for lvl in LEVELS:\n",
    "        print(\"\\n\" + \"=\"*24 + f\"  START {lvl}  \" + \"=\"*24)\n",
    "        process_level(lvl)\n",
    "    print(\"\\nðŸŽ‰ Bitti: SonuÃ§lar data/ratings/deepseek_ratings/ altÄ±nda ratings_reasoner_{LEVEL}.json dosyalarÄ±na yazÄ±ldÄ±.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f29c51a",
   "metadata": {},
   "source": [
    "# === DEBUG: 2 gÃ¶revle uÃ§tan uca test (DeepSeek-Chat) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae4905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "[1/2] TASK ID: A1_age | LEVEL=A1 | WORD=age\n",
      "------------------------------------------------------------------------------------------\n",
      ">> PROMPT (ilk 600 karakter):\n",
      "You are a professional CEFR-aligned English sentence evaluator.\n",
      "\n",
      "Your task is to evaluate 6 example sentences that all use the target word: \"age\" at CEFR level: A1.\n",
      "\n",
      "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
      "\n",
      "1. **Word Usage** â€“ Is the target word used correctly and meaningfully in context?\n",
      "2. **Clarity** â€“ Is the sentence understandable and suitable for the given CEFR level?\n",
      "3. **Grammar** â€“ Is the grammar accurate and appropriate for the level?\n",
      "4. **Naturalness** â€“ Does the sentence sound fluent and natural to a native speaker?\n",
      "\n",
      "âš ï¸ Important Instructions:\n",
      "- **Only return numerical ratings** for each criterion.\n",
      "- **Do not include any explanations, comments, or justifications.**\n",
      "- Follow the exact output format below.\n",
      "\n",
      "### Output Format:\n",
      "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \n",
      "Sentence B: ...  \n",
      "Sentence C: ...  \n",
      "Sentence D: ...  \n",
      "Sentence E: ...  \n",
      "Sentence F: ...  \n",
      "\n",
      "### Sentences:\n",
      "Sentence A: My birthday is on January 12th.\n",
      "Sentence B: My age is twenty-five years old.\n",
      "Sentence C: I am 20 years old.\n",
      "Sentence D: I am 10 years old, and I love playing with my pet dog.\n",
      "Sentence E: My age is seven years old.\n",
      "Sentence F: I am ten years old.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      ">> MAPPING LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      ">> MAPPING SENTENCE PREVIEW:\n",
      "   Sentence A: My birthday is on January 12th.\n",
      "   Sentence B: My age is twenty-five years old.\n",
      "   Sentence C: I am 20 years old.\n",
      "   Sentence D: I am 10 years old, and I love playing with my pet dog.\n",
      "   Sentence E: My age is seven years old.\n",
      "   Sentence F: I am ten years old.\n",
      "------------------------------------------------------------------------------------------\n",
      ">> RAW REPLY:\n",
      "Sentence A: 1, 3, 4, 4  \n",
      "Sentence B: 3, 3, 3, 3  \n",
      "Sentence C: 5, 5, 5, 5  \n",
      "Sentence D: 4, 5, 5, 5  \n",
      "Sentence E: 3, 3, 3, 3  \n",
      "Sentence F: 5, 5, 5, 5\n",
      "------------------------------------------------------------------------------------------\n",
      ">> PARSED LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      "âœ… PARSE OK & LABELS MATCH & SCORES IN RANGE\n",
      "â†’ Sentence A | model=Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf | My birthday is on January 12th.\n",
      "   scores: {'word_usage': 1, 'clarity': 3, 'grammar': 4, 'naturalness': 4}\n",
      "â†’ Sentence B | model=Claude Sonnet 4 | My age is twenty-five years old.\n",
      "   scores: {'word_usage': 3, 'clarity': 3, 'grammar': 3, 'naturalness': 3}\n",
      "==========================================================================================\n",
      "[2/2] TASK ID: A1_animal | LEVEL=A1 | WORD=animal\n",
      "------------------------------------------------------------------------------------------\n",
      ">> PROMPT (ilk 600 karakter):\n",
      "You are a professional CEFR-aligned English sentence evaluator.\n",
      "\n",
      "Your task is to evaluate 6 example sentences that all use the target word: \"animal\" at CEFR level: A1.\n",
      "\n",
      "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
      "\n",
      "1. **Word Usage** â€“ Is the target word used correctly and meaningfully in context?\n",
      "2. **Clarity** â€“ Is the sentence understandable and suitable for the given CEFR level?\n",
      "3. **Grammar** â€“ Is the grammar accurate and appropriate for the level?\n",
      "4. **Naturalness** â€“ Does the sentence sound fluent and natural to a native speaker?\n",
      "\n",
      "âš ï¸ Important Instructions:\n",
      "- **Only return numerical ratings** for each criterion.\n",
      "- **Do not include any explanations, comments, or justifications.**\n",
      "- Follow the exact output format below.\n",
      "\n",
      "### Output Format:\n",
      "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \n",
      "Sentence B: ...  \n",
      "Sentence C: ...  \n",
      "Sentence D: ...  \n",
      "Sentence E: ...  \n",
      "Sentence F: ...  \n",
      "\n",
      "### Sentences:\n",
      "Sentence A: This is a dog, a cat, and a bird. They are animals.\n",
      "Sentence B: A cat is a small animal.\n",
      "Sentence C: The dog is a friendly animal.\n",
      "Sentence D: I have a pet animal called Max.\n",
      "Sentence E: My favorite animal is the elephant, which is very big and grey.\n",
      "Sentence F: The cat is a pet animal.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      ">> MAPPING LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      ">> MAPPING SENTENCE PREVIEW:\n",
      "   Sentence A: This is a dog, a cat, and a bird. They are animals.\n",
      "   Sentence B: A cat is a small animal.\n",
      "   Sentence C: The dog is a friendly animal.\n",
      "   Sentence D: I have a pet animal called Max.\n",
      "   Sentence E: My favorite animal is the elephant, which is very big and grey.\n",
      "   Sentence F: The cat is a pet animal.\n",
      "------------------------------------------------------------------------------------------\n",
      ">> RAW REPLY:\n",
      "Sentence A: 5, 5, 5, 5  \n",
      "Sentence B: 5, 5, 5, 5  \n",
      "Sentence C: 5, 5, 5, 5  \n",
      "Sentence D: 4, 5, 5, 4  \n",
      "Sentence E: 5, 4, 4, 4  \n",
      "Sentence F: 5, 5, 5, 5\n",
      "------------------------------------------------------------------------------------------\n",
      ">> PARSED LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      "âœ… PARSE OK & LABELS MATCH & SCORES IN RANGE\n",
      "â†’ Sentence A | model=Ministral-8B-Instruct-2410.Q4_K_M.gguf | This is a dog, a cat, and a bird. They are animals.\n",
      "   scores: {'word_usage': 5, 'clarity': 5, 'grammar': 5, 'naturalness': 5}\n",
      "â†’ Sentence B | model=Gemini 2.5 Flash | A cat is a small animal.\n",
      "   scores: {'word_usage': 5, 'clarity': 5, 'grammar': 5, 'naturalness': 5}\n",
      "==========================================================================================\n",
      "ðŸŽ‰ Test tamam: 2 gÃ¶rev iÃ§in prompt â†’ reply â†’ parse â†’ mapping doÄŸrulandÄ±.\n"
     ]
    }
   ],
   "source": [
    "# === DEBUG: 2 gÃ¶revle uÃ§tan uca test hÃ¼cresi ===\n",
    "\n",
    "import os, json, re, textwrap\n",
    "from typing import Dict\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---- Ayarlar ----\n",
    "LEVEL = \"A1\"  # burada test etmek istediÄŸin seviyeyi seÃ§ (A1, A2, B1, B2, C1)\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "MODEL_NAME = \"deepseek-chat\"\n",
    "\n",
    "# ---- Ortam / Ä°stemci ----\n",
    "load_dotenv(find_dotenv())\n",
    "API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"DEEPSEEK_API_KEY bulunamadÄ±. .env veya ortam deÄŸiÅŸkenini kontrol et.\")\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "# ---- Yollar ----\n",
    "root = os.getcwd()\n",
    "tasks_path = os.path.abspath(os.path.join(root, \"..\", \"data\", \"tasks\", f\"tasks_{LEVEL}.json\"))\n",
    "\n",
    "# ---- Parser ----\n",
    "def parse_response(response_text: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Beklenen satÄ±rlar:\n",
    "      Sentence A: 4, 4, 5, 4\n",
    "    DÃ¶nen dict anahtarlarÄ±: \"Sentence A\" ... \"Sentence F\"\n",
    "    \"\"\"\n",
    "    pattern = r\"Sentence\\s*([A-F])\\s*:\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\"\n",
    "    results = {}\n",
    "    for m in re.finditer(pattern, response_text):\n",
    "        label = f\"Sentence {m.group(1)}\"\n",
    "        scores = list(map(int, m.groups()[1:]))\n",
    "        results[label] = {\n",
    "            \"word_usage\":  scores[0],\n",
    "            \"clarity\":     scores[1],\n",
    "            \"grammar\":     scores[2],\n",
    "            \"naturalness\": scores[3],\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def assert_parsed_ok(parsed, mapping, task_id):\n",
    "    # Etiket eÅŸleÅŸmesi\n",
    "    expected = set(mapping.keys())                 # {\"Sentence A\", ..., \"Sentence F\"}\n",
    "    got = set(parsed.keys())\n",
    "    missing = expected - got\n",
    "    extra   = got - expected\n",
    "    if missing or extra:\n",
    "        raise ValueError(f\"[PARSE MISMATCH] task={task_id} missing={sorted(missing)} extra={sorted(extra)}\")\n",
    "    # Skor aralÄ±ÄŸÄ±\n",
    "    for lbl, r in parsed.items():\n",
    "        for k, v in r.items():\n",
    "            assert isinstance(v, int) and 1 <= v <= 5, f\"[SCORE RANGE] task={task_id} {lbl}/{k} -> {v}\"\n",
    "\n",
    "# ---- YardÄ±mcÄ±: kÄ±sa cÃ¼mle Ã¶nizleme ----\n",
    "def preview(s: str, n=80):\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    return s if len(s) <= n else s[:n] + \"...\"\n",
    "\n",
    "# ---- Ã‡alÄ±ÅŸtÄ±r ----\n",
    "with open(tasks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks = json.load(f)\n",
    "\n",
    "tasks = tasks[:2]  # SADECE Ä°LK 2 GÃ–REV\n",
    "\n",
    "for idx, task in enumerate(tasks, start=1):\n",
    "    prompt  = task[\"prompt\"]\n",
    "    mapping = task[\"mapping\"]\n",
    "    task_id = task[\"task_id\"]\n",
    "    word    = task[\"word\"]\n",
    "    level   = task[\"level\"]\n",
    "\n",
    "    print(\"=\"*90)\n",
    "    print(f\"[{idx}/2] TASK ID: {task_id} | LEVEL={level} | WORD={word}\")\n",
    "    print(\"-\"*90)\n",
    "    print(\">> PROMPT (ilk 600 karakter):\")\n",
    "    #print(textwrap.shorten(prompt, width=600, placeholder=\" ...\"))\n",
    "    print(prompt)\n",
    "    print(\"-\"*90)\n",
    "    print(\">> MAPPING LABELS:\", list(mapping.keys()))\n",
    "    print(\">> MAPPING SENTENCE PREVIEW:\")\n",
    "    for lbl in [\"Sentence A\",\"Sentence B\",\"Sentence C\",\"Sentence D\",\"Sentence E\",\"Sentence F\"]:\n",
    "        sent = mapping[lbl][\"sentence\"]\n",
    "        print(f\"   {lbl}: {preview(sent)}\")\n",
    "\n",
    "    # --- API Ã§aÄŸrÄ±sÄ± ---\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        stream=False,\n",
    "    )\n",
    "    reply = resp.choices[0].message.content\n",
    "\n",
    "    print(\"-\"*90)\n",
    "    print(\">> RAW REPLY:\")\n",
    "    print(reply)\n",
    "\n",
    "    # --- Parse & doÄŸrulama ---\n",
    "    parsed = parse_response(reply)\n",
    "    print(\"-\"*90)\n",
    "    print(\">> PARSED LABELS:\", list(parsed.keys()))\n",
    "    assert_parsed_ok(parsed, mapping, task_id)\n",
    "    print(\"âœ… PARSE OK & LABELS MATCH & SCORES IN RANGE\")\n",
    "\n",
    "    # --- EÅŸleÅŸtirilmiÅŸ Ã¶rnek Ã§Ä±ktÄ± (ilk 2 label gÃ¶sterelim) ---\n",
    "    show_labels = [\"Sentence A\",\"Sentence B\"]\n",
    "    for lbl in show_labels:\n",
    "        model_name = mapping[lbl][\"model\"]\n",
    "        sentence   = mapping[lbl][\"sentence\"]\n",
    "        scores     = parsed[lbl]\n",
    "        print(f\"â†’ {lbl} | model={model_name} | {preview(sentence)}\")\n",
    "        print(f\"   scores: {scores}\")\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ðŸŽ‰ Test tamam: 2 gÃ¶rev iÃ§in prompt â†’ reply â†’ parse â†’ mapping doÄŸrulandÄ±.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc145911",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24bb7d4c",
   "metadata": {},
   "source": [
    "# === DEBUG: 2 gÃ¶revle uÃ§tan uca test (OpenAI / ChatGPT) ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca8d36c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2be3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "[1/2] TASK ID: A1_age | LEVEL=A1 | WORD=age\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> PROMPT (tam hali):\n",
      "You are a professional CEFR-aligned English sentence evaluator.\n",
      "\n",
      "Your task is to evaluate 6 example sentences that all use the target word: \"age\" at CEFR level: A1.\n",
      "\n",
      "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
      "\n",
      "1) Word Usage â€” Is the given word used with the correct meaning and appropriately in context?\n",
      "2) Level Appropriateness â€” Are the tense, structure, and syntax appropriate for the target CEFR level (A1, A2, B1, B2, C1)?\n",
      "3) Grammatical Accuracy â€” Are the grammatical structures correct and suitable for the expected level (simple / intermediate / advanced)?\n",
      "4) Naturalness â€” Does the sentence sound natural and align with standard usage by native English speakers?\n",
      "\n",
      "âš ï¸ Important Instructions:\n",
      "- **Only return numerical ratings** for each criterion.\n",
      "- **Do not include any explanations, comments, or justifications.**\n",
      "- Follow the exact output format below.\n",
      "\n",
      "### Output Format:\n",
      "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \n",
      "Sentence B: ...  \n",
      "Sentence C: ...  \n",
      "Sentence D: ...  \n",
      "Sentence E: ...  \n",
      "Sentence F: ...  \n",
      "\n",
      "### Sentences:\n",
      "Sentence A: I am ten years old.\n",
      "Sentence B: My age is twenty-five years old.\n",
      "Sentence C: I am 10 years old, and I love playing with my pet dog.\n",
      "Sentence D: My age is seven years old.\n",
      "Sentence E: My birthday is on January 12th.\n",
      "Sentence F: I am 20 years old.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> MAPPING LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      ">> MAPPING SENTENCE PREVIEW:\n",
      "   Sentence A: I am ten years old.\n",
      "   Sentence B: My age is twenty-five years old.\n",
      "   Sentence C: I am 10 years old, and I love playing with my pet dog.\n",
      "   Sentence D: My age is seven years old.\n",
      "   Sentence E: My birthday is on January 12th.\n",
      "   Sentence F: I am 20 years old.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> RAW REPLY:\n",
      "Sentence A: 1, 5, 5, 5\n",
      "Sentence B: 2, 5, 2, 2\n",
      "Sentence C: 1, 5, 5, 5\n",
      "Sentence D: 2, 5, 2, 2\n",
      "Sentence E: 1, 5, 5, 5\n",
      "Sentence F: 1, 5, 5, 5\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> PARSED LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      "âœ… PARSE OK & LABELS MATCH & SCORES IN RANGE\n",
      "â†’ Sentence A | model=GPT-4-turbo | I am ten years old.\n",
      "   scores: {'word_usage': 1, 'clarity': 5, 'grammar': 5, 'naturalness': 5}\n",
      "â†’ Sentence B | model=Claude Sonnet 4 | My age is twenty-five years old.\n",
      "   scores: {'word_usage': 2, 'clarity': 5, 'grammar': 2, 'naturalness': 2}\n",
      "====================================================================================================\n",
      "[2/2] TASK ID: A1_animal | LEVEL=A1 | WORD=animal\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> PROMPT (tam hali):\n",
      "You are a professional CEFR-aligned English sentence evaluator.\n",
      "\n",
      "Your task is to evaluate 6 example sentences that all use the target word: \"animal\" at CEFR level: A1.\n",
      "\n",
      "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
      "\n",
      "1) Word Usage â€” Is the given word used with the correct meaning and appropriately in context?\n",
      "2) Level Appropriateness â€” Are the tense, structure, and syntax appropriate for the target CEFR level (A1, A2, B1, B2, C1)?\n",
      "3) Grammatical Accuracy â€” Are the grammatical structures correct and suitable for the expected level (simple / intermediate / advanced)?\n",
      "4) Naturalness â€” Does the sentence sound natural and align with standard usage by native English speakers?\n",
      "\n",
      "âš ï¸ Important Instructions:\n",
      "- **Only return numerical ratings** for each criterion.\n",
      "- **Do not include any explanations, comments, or justifications.**\n",
      "- Follow the exact output format below.\n",
      "\n",
      "### Output Format:\n",
      "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \n",
      "Sentence B: ...  \n",
      "Sentence C: ...  \n",
      "Sentence D: ...  \n",
      "Sentence E: ...  \n",
      "Sentence F: ...  \n",
      "\n",
      "### Sentences:\n",
      "Sentence A: I have a pet animal called Max.\n",
      "Sentence B: A cat is a small animal.\n",
      "Sentence C: My favorite animal is the elephant, which is very big and grey.\n",
      "Sentence D: The dog is a friendly animal.\n",
      "Sentence E: This is a dog, a cat, and a bird. They are animals.\n",
      "Sentence F: The cat is a pet animal.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> MAPPING LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      ">> MAPPING SENTENCE PREVIEW:\n",
      "   Sentence A: I have a pet animal called Max.\n",
      "   Sentence B: A cat is a small animal.\n",
      "   Sentence C: My favorite animal is the elephant, which is very big and grey.\n",
      "   Sentence D: The dog is a friendly animal.\n",
      "   Sentence E: This is a dog, a cat, and a bird. They are animals.\n",
      "   Sentence F: The cat is a pet animal.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> RAW REPLY:\n",
      "Sentence A: 4, 5, 5, 3\n",
      "Sentence B: 5, 5, 5, 5\n",
      "Sentence C: 5, 3, 5, 5\n",
      "Sentence D: 5, 5, 5, 5\n",
      "Sentence E: 5, 5, 2, 2\n",
      "Sentence F: 4, 5, 5, 3\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">> PARSED LABELS: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      "âœ… PARSE OK & LABELS MATCH & SCORES IN RANGE\n",
      "â†’ Sentence A | model=Claude Sonnet 4 | I have a pet animal called Max.\n",
      "   scores: {'word_usage': 4, 'clarity': 5, 'grammar': 5, 'naturalness': 3}\n",
      "â†’ Sentence B | model=Gemini 2.5 Flash | A cat is a small animal.\n",
      "   scores: {'word_usage': 5, 'clarity': 5, 'grammar': 5, 'naturalness': 5}\n",
      "====================================================================================================\n",
      "ðŸŽ‰ Test tamam: 2 gÃ¶rev iÃ§in prompt â†’ reply â†’ parse â†’ mapping doÄŸrulandÄ±.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, json, re\n",
    "from typing import Dict\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---- Ayarlar ----\n",
    "LEVEL = \"A1\"                      # A1, A2, B1, B2, C1\n",
    "MODEL_NAME = \"gpt-5\"              # alternatif: \"gpt-5-mini\", \"gpt-4.1\"\n",
    "TEMPERATURE = 1.0                   # sayÄ±sal derecelendirme iÃ§in deterministik\n",
    "\n",
    "# ---- Ortam / Ä°stemci ----\n",
    "load_dotenv(find_dotenv())\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY bulunamadÄ±. .env veya ortam deÄŸiÅŸkenini ayarla.\")\n",
    "client = OpenAI(api_key=API_KEY)  # OpenAI iÃ§in base_url vermiyoruz\n",
    "\n",
    "# ---- Yollar ----\n",
    "root = os.getcwd()\n",
    "tasks_path = os.path.abspath(os.path.join(root, \"..\", \"data\", \"tasks\", f\"tasks_{LEVEL}.json\"))\n",
    "\n",
    "# ---- Parser ----\n",
    "def parse_response(response_text: str) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Beklenen satÄ±rlar:\n",
    "      Sentence A: 4, 4, 5, 4\n",
    "    DÃ¶nen dict anahtarlarÄ±: \"Sentence A\" ... \"Sentence F\"\n",
    "    \"\"\"\n",
    "    pattern = r\"Sentence\\s*([A-F])\\s*:\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\"\n",
    "    results = {}\n",
    "    for m in re.finditer(pattern, response_text):\n",
    "        label = f\"Sentence {m.group(1)}\"\n",
    "        scores = list(map(int, m.groups()[1:]))\n",
    "        results[label] = {\n",
    "            \"word_usage\":  scores[0],\n",
    "            \"clarity\":     scores[1],\n",
    "            \"grammar\":     scores[2],\n",
    "            \"naturalness\": scores[3],\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def assert_parsed_ok(parsed, mapping, task_id):\n",
    "    expected = set(mapping.keys())  # {\"Sentence A\",..., \"Sentence F\"}\n",
    "    got = set(parsed.keys())\n",
    "    missing = expected - got\n",
    "    extra   = got - expected\n",
    "    if missing or extra:\n",
    "        raise ValueError(f\"[PARSE MISMATCH] task={task_id} missing={sorted(missing)} extra={sorted(extra)}\")\n",
    "    for lbl, r in parsed.items():\n",
    "        for k, v in r.items():\n",
    "            assert isinstance(v, int) and 1 <= v <= 5, f\"[SCORE RANGE] task={task_id} {lbl}/{k} -> {v}\"\n",
    "\n",
    "def preview(s: str, n=80):\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    return s if len(s) <= n else s[:n] + \"...\"\n",
    "\n",
    "# ---- Ã‡alÄ±ÅŸtÄ±r ----\n",
    "with open(tasks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    tasks = json.load(f)\n",
    "\n",
    "tasks = tasks[:2]  # SADECE Ä°LK 2 GÃ–REV\n",
    "\n",
    "for idx, task in enumerate(tasks, start=1):\n",
    "    prompt  = task[\"prompt\"]\n",
    "    mapping = task[\"mapping\"]\n",
    "    task_id = task[\"task_id\"]\n",
    "    word    = task[\"word\"]\n",
    "    level   = task[\"level\"]\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(f\"[{idx}/2] TASK ID: {task_id} | LEVEL={level} | WORD={word}\")\n",
    "    print(\"-\"*100)\n",
    "    print(\">> PROMPT (tam hali):\")\n",
    "    print(prompt)\n",
    "    print(\"-\"*100)\n",
    "    print(\">> MAPPING LABELS:\", list(mapping.keys()))\n",
    "    print(\">> MAPPING SENTENCE PREVIEW:\")\n",
    "    for lbl in [\"Sentence A\",\"Sentence B\",\"Sentence C\",\"Sentence D\",\"Sentence E\",\"Sentence F\"]:\n",
    "        sent = mapping[lbl][\"sentence\"]\n",
    "        print(f\"   {lbl}: {preview(sent)}\")\n",
    "\n",
    "    # --- OpenAI API Ã§aÄŸrÄ±sÄ± ---\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=TEMPERATURE,\n",
    "        stream=False,\n",
    "    )\n",
    "    reply = resp.choices[0].message.content\n",
    "\n",
    "    print(\"-\"*100)\n",
    "    print(\">> RAW REPLY:\")\n",
    "    print(reply)\n",
    "\n",
    "    # --- Parse & doÄŸrulama ---\n",
    "    parsed = parse_response(reply)\n",
    "    print(\"-\"*100)\n",
    "    print(\">> PARSED LABELS:\", list(parsed.keys()))\n",
    "    assert_parsed_ok(parsed, mapping, task_id)\n",
    "    print(\"âœ… PARSE OK & LABELS MATCH & SCORES IN RANGE\")\n",
    "\n",
    "    # --- EÅŸleÅŸtirilmiÅŸ Ã¶rnek Ã§Ä±ktÄ± (A ve B'yi gÃ¶ster) ---\n",
    "    for lbl in [\"Sentence A\",\"Sentence B\"]:\n",
    "        model_name = mapping[lbl][\"model\"]\n",
    "        sentence   = mapping[lbl][\"sentence\"]\n",
    "        scores     = parsed[lbl]\n",
    "        print(f\"â†’ {lbl} | model={model_name} | {preview(sentence)}\")\n",
    "        print(f\"   scores: {scores}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ðŸŽ‰ Test tamam: 2 gÃ¶rev iÃ§in prompt â†’ reply â†’ parse â†’ mapping doÄŸrulandÄ±.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704cdc4",
   "metadata": {},
   "source": [
    "# GPT-5 Modeline Prompt GÃ¶nderip SonuÃ§larÄ± Alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9742ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================  START A1  ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing A1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [12:19<00:00, 73.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… A1: 60 rows saved â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/chatgpt_ratings/ratings_A1.json\n",
      "\n",
      "==================  START A2  ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing A2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [07:30<00:00, 45.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… A2: 60 rows saved â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/chatgpt_ratings/ratings_A2.json\n",
      "\n",
      "==================  START B1  ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing B1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [08:59<00:00, 53.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… B1: 60 rows saved â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/chatgpt_ratings/ratings_B1.json\n",
      "\n",
      "==================  START B2  ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing B2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [07:48<00:00, 46.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… B2: 60 rows saved â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/chatgpt_ratings/ratings_B2.json\n",
      "\n",
      "==================  START C1  ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing C1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [10:28<00:00, 62.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… C1: 60 rows saved â†’ /home/user/Documents/Tez/Deneyler/LLM_Degerlendirme/data/ratings/chatgpt_ratings/ratings_C1.json\n",
      "\n",
      "ðŸŽ‰ Done: All levels written to data/ratings/chatgpt_ratings/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# ========= ENV / CLIENT =========\n",
    "load_dotenv(find_dotenv())\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY not set. Put it in .env or export it.\")\n",
    "\n",
    "# Model adÄ±nÄ± burada deÄŸiÅŸtir: (\"gpt-5\", \"gpt-5-mini\", \"gpt-4.1\" vs.)\n",
    "MODEL_NAME = \"gpt-5\"\n",
    "TEMPERATURE = 1.0                   # yaratÄ±cÄ± cevaplar iÃ§in, artÄ±k sadece 1.0 kabul ediliyormuÅŸ\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# ========= PATHS =========\n",
    "root = os.getcwd()\n",
    "tasks_dir = os.path.abspath(os.path.join(root, \"..\", \"data\", \"tasks\"))\n",
    "ratings_root = os.path.abspath(os.path.join(root, \"..\", \"data\", \"ratings\"))\n",
    "output_dir = os.path.join(ratings_root, \"chatgpt_ratings\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "RAW_LOG = False\n",
    "raw_dir = os.path.join(output_dir, \"raw_logs\")\n",
    "if RAW_LOG:\n",
    "    os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "# ========= PARSER =========\n",
    "def parse_response(response_text: str) -> Dict[str, Dict[str, int]]:\n",
    "    pattern = r\"Sentence\\s*([A-F])\\s*:\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\\s*,\\s*([1-5])\"\n",
    "    results = {}\n",
    "    for m in re.finditer(pattern, response_text):\n",
    "        label = f\"Sentence {m.group(1)}\"\n",
    "        s = list(map(int, m.groups()[1:]))\n",
    "        results[label] = {\"word_usage\": s[0], \"clarity\": s[1], \"grammar\": s[2], \"naturalness\": s[3]}\n",
    "    return results\n",
    "\n",
    "def average_scores(score_dicts: List[Dict[str, Dict[str, int]]]) -> Dict[str, Dict[str, float]]:\n",
    "    merged: Dict[str, Dict[str, List[float]]] = {}\n",
    "    for sd in score_dicts:\n",
    "        for label, metrics in sd.items():\n",
    "            merged.setdefault(label, {k: [] for k in [\"word_usage\",\"clarity\",\"grammar\",\"naturalness\"]})\n",
    "            for k, v in metrics.items():\n",
    "                merged[label][k].append(float(v))\n",
    "    averaged: Dict[str, Dict[str, float]] = {}\n",
    "    for label, lists in merged.items():\n",
    "        averaged[label] = {k: (sum(vals)/len(vals) if vals else 0.0) for k, vals in lists.items()}\n",
    "    return averaged\n",
    "\n",
    "# ========= API CALL =========\n",
    "def call_openai(prompt: str, retries: int = 3, backoff: float = 2.0) -> str:\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=TEMPERATURE,\n",
    "                stream=False,\n",
    "            )\n",
    "            return resp.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] API call failed (attempt {attempt}/{retries}): {e}\")\n",
    "            if attempt < retries:\n",
    "                time.sleep(backoff ** attempt)\n",
    "            else:\n",
    "                raise\n",
    "    return \"\"\n",
    "\n",
    "# ========= RUN ONE LEVEL =========\n",
    "def process_level(level: str, N_EVALS: int = 2, skip_if_exists: bool = False):\n",
    "    tasks_path = os.path.join(tasks_dir, f\"tasks_{level}.json\")\n",
    "    out_path   = os.path.join(output_dir, f\"ratings_{level}.json\")\n",
    "\n",
    "    if not os.path.exists(tasks_path):\n",
    "        print(f\"[SKIP] No tasks file: {tasks_path}\")\n",
    "        return\n",
    "\n",
    "    if skip_if_exists and os.path.exists(out_path):\n",
    "        print(f\"[SKIP] Output exists â†’ {out_path}\")\n",
    "        return\n",
    "\n",
    "    with open(tasks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tasks = json.load(f)\n",
    "\n",
    "    all_ratings = []\n",
    "    for task in tqdm(tasks, desc=f\"Processing {level}\"):\n",
    "        prompt  = task[\"prompt\"]\n",
    "        mapping = task[\"mapping\"]\n",
    "        task_id = task[\"task_id\"]\n",
    "        word    = task[\"word\"]\n",
    "\n",
    "        try:\n",
    "            runs = []\n",
    "            for run_idx in range(N_EVALS):\n",
    "                reply = call_openai(prompt)\n",
    "                if RAW_LOG:\n",
    "                    with open(os.path.join(raw_dir, f\"{level}__{task_id}__run{run_idx+1}__prompt.txt\"), \"w\", encoding=\"utf-8\") as pf:\n",
    "                        pf.write(prompt)\n",
    "                    with open(os.path.join(raw_dir, f\"{level}__{task_id}__run{run_idx+1}__reply.txt\"), \"w\", encoding=\"utf-8\") as rf:\n",
    "                        rf.write(reply)\n",
    "                runs.append(parse_response(reply))\n",
    "\n",
    "            averaged = average_scores(runs)\n",
    "\n",
    "            for label, rating in averaged.items():\n",
    "                if label not in mapping:\n",
    "                    print(f\"[WARN] Unmatched label: {label} (task_id={task_id})\")\n",
    "                    continue\n",
    "                all_ratings.append({\n",
    "                    \"task_id\":  task_id,\n",
    "                    \"model\":    mapping[label][\"model\"],\n",
    "                    \"level\":    level,\n",
    "                    \"word\":     word,\n",
    "                    \"label\":    label,\n",
    "                    \"sentence\": mapping[label][\"sentence\"],\n",
    "                    \"ratings\":  {\n",
    "                        \"word_usage\": round(rating.get(\"word_usage\", 0.0), 1),\n",
    "                        \"clarity\":     round(rating.get(\"clarity\", 0.0), 1),\n",
    "                        \"grammar\":     round(rating.get(\"grammar\", 0.0), 1),\n",
    "                        \"naturalness\": round(rating.get(\"naturalness\", 0.0), 1),\n",
    "                    }\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] level={level} task={task_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_ratings, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    task_ids = {r[\"task_id\"] for r in all_ratings}\n",
    "    expected_rows = 6 * len(task_ids)\n",
    "    print(f\"âœ… {level}: {len(all_ratings)} rows saved â†’ {out_path}\")\n",
    "    if len(all_ratings) != expected_rows:\n",
    "        print(f\"âš ï¸  {level}: Row count mismatch (expected {expected_rows}, got {len(all_ratings)}).\")\n",
    "\n",
    "# ========= MAIN =========\n",
    "if __name__ == \"__main__\":\n",
    "    LEVELS = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\"]\n",
    "    for lvl in LEVELS:\n",
    "        print(\"\\n\" + \"=\"*18 + f\"  START {lvl}  \" + \"=\"*18)\n",
    "        process_level(lvl, N_EVALS=2, skip_if_exists=False)\n",
    "    print(\"\\nðŸŽ‰ Done: All levels written to data/ratings/chatgpt_ratings/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa9b78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cbe9887",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
