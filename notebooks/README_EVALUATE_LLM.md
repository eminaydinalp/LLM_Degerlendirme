# LLM DeÄŸerlendirme Scripti KullanÄ±m KÄ±lavuzu

## ğŸ¯ Genel BakÄ±ÅŸ

`evaluate_with_llm.py` scripti, farklÄ± LLM'lerin Ã¼rettiÄŸi cÃ¼mleleri seÃ§tiÄŸiniz bir deÄŸerlendirici model ile otomatik olarak deÄŸerlendirmenizi saÄŸlar.

## ğŸ“‹ Ã–zellikler

- âœ… **Parametreli KullanÄ±m**: Komut satÄ±rÄ±ndan model, seviye, grup ve ayarlarÄ± belirleyebilirsiniz
- âœ… **Grup BazlÄ± Ä°ÅŸlem**: Her seviye iÃ§in farklÄ± task gruplarÄ±nÄ± ayrÄ± ayrÄ± deÄŸerlendirebilirsiniz
- âœ… **Ã‡oklu Model DesteÄŸi**: DeepSeek, OpenAI GPT modelleri
- âœ… **Organize Ã‡Ä±ktÄ±lar**: Seviye ve grup bazlÄ± klasÃ¶r yapÄ±sÄ±
- âœ… **Esneklik**: Ä°stediÄŸiniz seviyeleri ve gruplarÄ± seÃ§ebilirsiniz (A1-C1, Grup 1,2,3...)
- âœ… **Tekrar MekanizmasÄ±**: GÃ¼venilir sonuÃ§lar iÃ§in N tekrar ve ortalama alma
- âœ… **Hata YÃ¶netimi**: Otomatik retry/backoff mekanizmasÄ±
- âœ… **Debug DesteÄŸi**: Ä°steÄŸe baÄŸlÄ± raw log kaydetme

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Temel KullanÄ±m

```bash
# DeepSeek Chat ile A1 seviyesini, Grup 1'i deÄŸerlendir
python evaluate_with_llm.py --model deepseek-chat --levels A1 --group 1

# GPT-5 ile tÃ¼m seviyeleri, Grup 1'i deÄŸerlendir
python evaluate_with_llm.py --model gpt-5 --levels A1 A2 B1 B2 C1 --group 1
```

### 2. GeliÅŸmiÅŸ KullanÄ±m

```bash
# DeepSeek Reasoner ile B1 ve B2, Grup 2'yi 3 tekrarla
python evaluate_with_llm.py --model deepseek-reasoner --levels B1 B2 --group 2 --n-evals 3

# YÃ¼ksek temperature ile yaratÄ±cÄ± deÄŸerlendirme
python evaluate_with_llm.py --model gpt-4o --levels A1 --group 1 --temperature 1.5

# Mevcut sonuÃ§larÄ± atla
python evaluate_with_llm.py --model gpt-5-mini --group 1 --skip-existing

# Debug modunda (raw loglarÄ± kaydet)
python evaluate_with_llm.py --model deepseek-chat --levels A1 --group 1 --save-raw-logs
```

## ğŸ“Š Desteklenen Modeller

| Model | Provider | AÃ§Ä±klama |
|-------|----------|----------|
| `deepseek-chat` | DeepSeek | Temel chat modeli |
| `deepseek-reasoner` | DeepSeek | GeliÅŸmiÅŸ akÄ±l yÃ¼rÃ¼tme modeli |
| `gpt-4o` | OpenAI | GPT-4 Optimized |
| `gpt-5` | OpenAI | En gÃ¼ncel GPT modeli |
| `gpt-5-mini` | OpenAI | Hafif GPT-5 versiyonu |
| `gpt-4.1` | OpenAI | GPT-4.1 modeli |

## ğŸ”§ Parametreler

### Zorunlu Parametreler

- `--model`: DeÄŸerlendirici model seÃ§imi
  ```bash
  --model deepseek-chat
  ```

- `--group`: DeÄŸerlendirilecek grup numarasÄ±
  ```bash
  --group 1
  ```

### Opsiyonel Parametreler

- `--levels`: DeÄŸerlendirilecek seviyeler (varsayÄ±lan: tÃ¼mÃ¼)
  ```bash
  --levels A1 A2 B1
  ```

- `--temperature`: Model temperature (0.0-2.0, varsayÄ±lan: 1.0)
  ```bash
  --temperature 1.5
  ```

- `--n-evals`: Her gÃ¶rev iÃ§in tekrar sayÄ±sÄ± (varsayÄ±lan: 2)
  ```bash
  --n-evals 3
  ```

- `--skip-existing`: Mevcut sonuÃ§ dosyalarÄ±nÄ± atla
  ```bash
  --skip-existing
  ```

- `--save-raw-logs`: Ham prompt ve cevaplarÄ± kaydet (debug)
  ```bash
  --save-raw-logs
  ```

- `--tasks-dir`: Tasks dizini Ã¶zel yolu
  ```bash
  --tasks-dir /path/to/tasks
  ```

- `--output-dir`: Ã‡Ä±ktÄ± dizini Ã¶zel yolu
  ```bash
  --output-dir /path/to/output
  ```

## ğŸ“ Dosya YapÄ±sÄ±

### Girdi
```
data/tasks/
  â”œâ”€â”€ A1/
  â”‚   â”œâ”€â”€ tasks_A1_1.json
  â”‚   â”œâ”€â”€ tasks_A1_2.json
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ A2/
  â”‚   â”œâ”€â”€ tasks_A2_1.json
  â”‚   â””â”€â”€ ...
  â””â”€â”€ ...
```

### Ã‡Ä±ktÄ±
```
data/ratings/
  â”œâ”€â”€ deepseek_ratings/
  â”‚   â”œâ”€â”€ A1/
  â”‚   â”‚   â”œâ”€â”€ ratings_A1_1.json
  â”‚   â”‚   â”œâ”€â”€ ratings_A1_2.json
  â”‚   â”‚   â””â”€â”€ ...
  â”‚   â”œâ”€â”€ A2/
  â”‚   â”‚   â””â”€â”€ ...
  â”‚   â””â”€â”€ raw_logs/  (--save-raw-logs ile)
  â”‚
  â””â”€â”€ chatgpt_ratings/
      â”œâ”€â”€ A1/
      â”‚   â”œâ”€â”€ ratings_A1_1.json
      â”‚   â””â”€â”€ ...
      â””â”€â”€ raw_logs/
```

## ğŸ”‘ API Key AyarlarÄ±

Scriptler `.env` dosyasÄ±ndan API key'leri okur:

```env
# .env dosyasÄ±
DEEPSEEK_API_KEY=your_deepseek_key_here
OPENAI_API_KEY=your_openai_key_here
```

## ğŸ“ Ã‡Ä±ktÄ± FormatÄ±

Her sonuÃ§ dosyasÄ± ÅŸu yapÄ±da JSON iÃ§erir:

```json
[
  {
    "task_id": "A1_task_001",
    "model": "Claude_Sonnet_4.5",
    "level": "A1",
    "group": 1,
    "word": "book",
    "label": "Sentence A",
    "sentence": "I like to read books.",
    "ratings": {
      "word_usage": 4.5,
      "clarity": 4.0,
      "grammar": 5.0,
      "naturalness": 4.5
    },
    "evaluator": "deepseek-chat"
  }
]
```

## ğŸ’¡ KullanÄ±m SenaryolarÄ±

### Senaryo 1: Tek Seviye HÄ±zlÄ± Test (Grup 1)
```bash
python evaluate_with_llm.py --model gpt-5 --levels A1 --group 1 --n-evals 1
```

### Senaryo 2: Production Run (TÃ¼m Seviyeler, Grup 1)
```bash
python evaluate_with_llm.py --model deepseek-reasoner --group 1 --n-evals 3 --skip-existing
```

### Senaryo 3: Model KarÅŸÄ±laÅŸtÄ±rmasÄ± (Grup 1)
```bash
# Her model ile aynÄ± seviyeleri deÄŸerlendir
python evaluate_with_llm.py --model deepseek-chat --levels A1 A2 --group 1
python evaluate_with_llm.py --model gpt-5 --levels A1 A2 --group 1
python evaluate_with_llm.py --model gpt-4o --levels A1 A2 --group 1
```

### Senaryo 4: Debug / Sorun Giderme
```bash
python evaluate_with_llm.py --model deepseek-chat --levels A1 --group 1 --n-evals 1 --save-raw-logs
```

### Senaryo 5: FarklÄ± GruplarÄ± DeÄŸerlendirme
```bash
# Grup 1'i deÄŸerlendir
python evaluate_with_llm.py --model gpt-5 --levels A1 A2 --group 1

# Grup 2'yi deÄŸerlendir
python evaluate_with_llm.py --model gpt-5 --levels A1 A2 --group 2
```

## ğŸ” Yeni Model Ekleme

Yeni bir model eklemek iÃ§in `MODEL_CONFIGS` sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ dÃ¼zenleyin:

```python
MODEL_CONFIGS = {
    # ...mevcut modeller...
    
    "yeni-model": {
        "provider": "openai",  # veya "deepseek"
        "base_url": None,      # veya Ã¶zel URL
        "api_key_env": "YENÄ°_MODEL_API_KEY",
        "model_name": "yeni-model-adÄ±",
        "output_subdir": "yeni_model_ratings",
        "output_prefix": "ratings_yenimodel"
    }
}
```

## âš ï¸ Ã–nemli Notlar

1. **API Limitleri**: Rate limiting iÃ§in otomatik backoff mekanizmasÄ± var ama yine de dikkatli olun
2. **Maliyet**: OpenAI modelleri Ã¼cretli, her API Ã§aÄŸrÄ±sÄ± sayÄ±lÄ±r
3. **SÃ¼re**: TÃ¼m seviyeler iÃ§in (~1000 task) yaklaÅŸÄ±k 30-60 dakika sÃ¼rebilir
4. **Tekrar Edilebilirlik**: AynÄ± sonuÃ§larÄ± almak iÃ§in `temperature=0` kullanÄ±n

## ğŸ› Sorun Giderme

### API Key HatasÄ±
```
RuntimeError: DEEPSEEK_API_KEY ortam deÄŸiÅŸkeni tanÄ±mlÄ± deÄŸil!
```
**Ã‡Ã¶zÃ¼m**: `.env` dosyasÄ±nÄ± oluÅŸturun ve ilgili API key'i ekleyin

### Parse HatasÄ±
```
[UYARI] EÅŸleÅŸmeyen etiket: Sentence G (task_id=A1_task_001)
```
**Ã‡Ã¶zÃ¼m**: Model beklenmeyen format dÃ¶ndÃ¼. `--save-raw-logs` ile detaylÄ± log alÄ±n

### SatÄ±r SayÄ±sÄ± UyuÅŸmazlÄ±ÄŸÄ±
```
âš ï¸ A1: SatÄ±r sayÄ±sÄ± uyuÅŸmuyor (beklenen 600, gerÃ§ek 594)
```
**Ã‡Ã¶zÃ¼m**: BazÄ± task'lar baÅŸarÄ±sÄ±z olmuÅŸ. LoglarÄ± kontrol edin ve tekrar Ã§alÄ±ÅŸtÄ±rÄ±n

## ğŸ“ Destek

SorularÄ±nÄ±z iÃ§in:
- GitHub Issues
- README dosyasÄ±nÄ± kontrol edin
- Kod iÃ§indeki docstring'lere bakÄ±n

---

**Not**: Bu script, tez Ã§alÄ±ÅŸmanÄ±zda LLM deÄŸerlendirmelerini otomatikleÅŸtirmek iÃ§in tasarlanmÄ±ÅŸtÄ±r. Parametreleri ihtiyacÄ±nÄ±za gÃ¶re ayarlayabilirsiniz.
