{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0863d166-18c1-4a29-ae49-c43121aab666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Seviye: B1\n",
      "ğŸ“Š Grup: 1\n",
      "============================================================\n",
      "ğŸ“ Bulunan modeller: ['Claude_Sonnet_4.5', 'Gemini_Pro_2.5', 'Llama-3.2-1B-Instruct', 'Llama-3.2-1B-Instruct-FineTuned', 'Llama-3.2-8B-Instruct', 'mistralai_Ministral-8B-Instruct-2410']\n",
      "ğŸ“Š Toplam 6 model bulundu\n",
      "âœ… Claude_Sonnet_4.5: 10 kelime\n",
      "âœ… Gemini_Pro_2.5: 10 kelime\n",
      "âœ… Llama-3.2-1B-Instruct: 10 kelime\n",
      "âœ… Llama-3.2-1B-Instruct-FineTuned: 10 kelime\n",
      "âœ… Llama-3.2-8B-Instruct: 10 kelime\n",
      "âœ… mistralai_Ministral-8B-Instruct-2410: 10 kelime\n",
      "\n",
      "ğŸ“ Toplam 10 benzersiz kelime bulundu\n",
      "============================================================\n",
      "ğŸ·ï¸  Label'lar: ['Sentence A', 'Sentence B', 'Sentence C', 'Sentence D', 'Sentence E', 'Sentence F']\n",
      "\n",
      "âœ… 10 gÃ¶rev oluÅŸturuldu!\n",
      "ğŸ“ Dosya: /home/muhammet/Documents/Tez/LLM_Degerlendirme/notebooks/../data/tasks/tasks_B1_1.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================\n",
    "# PARAMETRELER - BURADAN AYARLAYIN\n",
    "# ============================================\n",
    "CEFR_LEVEL = \"B1\"  # \"A1\", \"A2\", \"B1\", \"B2\", \"C1\"\n",
    "GROUP_NUMBER = 1    # 1, 2, 3, ... (kaÃ§Ä±ncÄ± grup olduÄŸu)\n",
    "\n",
    "print(f\"ğŸ¯ Seviye: {CEFR_LEVEL}\")\n",
    "print(f\"ğŸ“Š Grup: {GROUP_NUMBER}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dizinleri ayarla\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, \"..\", \"data\", \"generated_sentences\", CEFR_LEVEL)\n",
    "data_dir = os.path.abspath(data_dir)\n",
    "\n",
    "output_base_dir = os.path.join(current_dir, \"..\", \"data\", \"tasks\")\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "# Model klasÃ¶rlerini bul\n",
    "model_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "model_dirs.sort()\n",
    "\n",
    "print(f\"ğŸ“ Bulunan modeller: {model_dirs}\")\n",
    "print(f\"ğŸ“Š Toplam {len(model_dirs)} model bulundu\")\n",
    "\n",
    "# Her modelden belirtilen grup numarasÄ±ndaki dosyayÄ± oku\n",
    "grouped_data = defaultdict(list)\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    model_path = os.path.join(data_dir, model_dir)\n",
    "    \n",
    "    # Belirtilen grup numarasÄ±ndaki dosyayÄ± seÃ§\n",
    "    # Format: ModelName_Level_GroupNumber.json\n",
    "    target_file = f\"{model_dir}_{CEFR_LEVEL}_{GROUP_NUMBER}.json\"\n",
    "    file_path = os.path.join(model_path, target_file)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"âš ï¸  Dosya bulunamadÄ±: {target_file}\")\n",
    "        continue\n",
    "    \n",
    "    # JSON dosyasÄ±nÄ± oku\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    model_name = data[\"model_name\"]\n",
    "    words = data[\"words\"]\n",
    "    sentences = data[\"sentences\"]\n",
    "    \n",
    "    print(f\"âœ… {model_name}: {len(words)} kelime\")\n",
    "    \n",
    "    # Her kelime iÃ§in veriyi grupla\n",
    "    for word, sentence in zip(words, sentences):\n",
    "        grouped_data[word].append({\n",
    "            \"model\": model_name,\n",
    "            \"sentence\": sentence\n",
    "        })\n",
    "\n",
    "print(f\"\\nğŸ“ Toplam {len(grouped_data)} benzersiz kelime bulundu\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Task'larÄ± oluÅŸtur\n",
    "tasks = []\n",
    "\n",
    "# Dinamik label oluÅŸtur (model sayÄ±sÄ±na gÃ¶re)\n",
    "num_models = len(model_dirs)\n",
    "labels = [f\"Sentence {chr(65+i)}\" for i in range(num_models)]  # A, B, C, D, E, F, ...\n",
    "print(f\"ğŸ·ï¸  Label'lar: {labels}\")\n",
    "\n",
    "# Prompt ÅŸablonu - dinamik olarak model sayÄ±sÄ±nÄ± kullan\n",
    "sentences_output_format = \"\\n\".join([f\"{label}: <Word Usage>, <Level Appropriateness>, <Grammar>, <Naturalness>\" for label in labels])\n",
    "\n",
    "prompt_template = \"\"\"You are a professional CEFR-aligned English sentence evaluator.\n",
    "\n",
    "Your task is to evaluate {num_sentences} example sentences that all use the target word: \"{{word}}\" at CEFR level: {{level}}.\n",
    "\n",
    "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
    "\n",
    "1) Word Usage â€” Is the given word used with the correct meaning and appropriately in context? **If the word is not used at all, give the lowest score.**\n",
    "2) Level Appropriateness â€” Are the tense, structure, and syntax appropriate for the target CEFR level (A1, A2, B1, B2, C1)?\n",
    "3) Grammatical Accuracy â€” Are the grammatical structures correct and suitable for the expected level (simple / intermediate / advanced)?\n",
    "4) Naturalness â€” Does the sentence sound natural and align with standard usage by native English speakers?\n",
    "\n",
    "âš ï¸ Important Instructions:\n",
    "- **Only return numerical ratings** for each criterion.\n",
    "- **Do not include any explanations, comments, or justifications.**\n",
    "- Follow the exact output format below.\n",
    "\n",
    "### Output Format:\n",
    "{output_format}\n",
    "\n",
    "### Sentences:\n",
    "{{sentences_block}}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = prompt_template.format(\n",
    "    num_sentences=num_models,\n",
    "    output_format=sentences_output_format\n",
    ")\n",
    "\n",
    "for word, sentence_data in grouped_data.items():\n",
    "    if len(sentence_data) != num_models:\n",
    "        print(f\"âš ï¸  '{word}' iÃ§in {len(sentence_data)} cÃ¼mle var ({num_models} gerekli), atlanÄ±yor.\")\n",
    "        continue\n",
    "    \n",
    "    # CÃ¼mleleri karÄ±ÅŸtÄ±r\n",
    "    random.shuffle(sentence_data)\n",
    "    \n",
    "    labeled_sentences = []\n",
    "    mapping = {}\n",
    "    sentences_block_lines = []\n",
    "    \n",
    "    for label, item in zip(labels, sentence_data):\n",
    "        sentence = item[\"sentence\"]\n",
    "        labeled_sentences.append((label, sentence))\n",
    "        mapping[label] = {\n",
    "            \"model\": item[\"model\"],\n",
    "            \"level\": CEFR_LEVEL,\n",
    "            \"word\": word,\n",
    "            \"sentence\": sentence\n",
    "        }\n",
    "        sentences_block_lines.append(f\"{label}: {sentence}\")\n",
    "    \n",
    "    # Promptu oluÅŸtur\n",
    "    sentences_block = \"\\n\".join(sentences_block_lines)\n",
    "    prompt = prompt_template.replace(\"{{word}}\", word).replace(\"{{level}}\", CEFR_LEVEL).replace(\"{{sentences_block}}\", sentences_block)\n",
    "    \n",
    "    # Task nesnesi\n",
    "    task = {\n",
    "        \"task_id\": f\"{CEFR_LEVEL}_{word}_{GROUP_NUMBER}\",\n",
    "        \"level\": CEFR_LEVEL,\n",
    "        \"group\": GROUP_NUMBER,\n",
    "        \"word\": word,\n",
    "        \"labeled_sentences\": labeled_sentences,\n",
    "        \"mapping\": mapping,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    \n",
    "    tasks.append(task)\n",
    "\n",
    "# DosyayÄ± kaydet - tasks klasÃ¶rÃ¼ direkt olarak output_base_dir altÄ±nda\n",
    "output_filename = f\"tasks_{CEFR_LEVEL}_{GROUP_NUMBER}.json\"\n",
    "output_filepath = os.path.join(output_base_dir, output_filename)\n",
    "\n",
    "with open(output_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tasks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… {len(tasks)} gÃ¶rev oluÅŸturuldu!\")\n",
    "print(f\"ğŸ“ Dosya: {output_filepath}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53680ef-b3d2-4de7-88c3-ca39554625d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“– KullanÄ±m KÄ±lavuzu\n",
    "\n",
    "## Parametreler:\n",
    "- **CEFR_LEVEL**: Hangi seviye iÃ§in task oluÅŸturulacak (A1, A2, B1, B2, C1)\n",
    "- **GROUP_NUMBER**: Hangi grup/batch iÃ§in (1, 2, 3, ...)\n",
    "\n",
    "## Ã–rnek:\n",
    "```python\n",
    "CEFR_LEVEL = \"A1\"\n",
    "GROUP_NUMBER = 1\n",
    "```\n",
    "\n",
    "## Ã–zellikler:\n",
    "- âœ… **Dinamik model sayÄ±sÄ±**: KlasÃ¶rde kaÃ§ model varsa hepsini kullanÄ±r (5, 6, 7... fark etmez)\n",
    "- âœ… **Otomatik label**: Model sayÄ±sÄ±na gÃ¶re A, B, C, D, E, F... oluÅŸturur\n",
    "- âœ… **Yeni dosya formatÄ±**: `ModelName_Level_GroupNumber.json`\n",
    "- âœ… **Word Usage kontrolÃ¼**: EÄŸer kelime kullanÄ±lmadÄ±ysa en dÃ¼ÅŸÃ¼k puan verilmesi gerektiÄŸi prompt'a eklendi\n",
    "\n",
    "## Ã‡Ä±ktÄ±:\n",
    "- **Dosya**: `data/tasks/tasks_A1_1.json` (Seviye bazlÄ± alt klasÃ¶r YOK)\n",
    "- Her kelime iÃ§in N model cÃ¼mlesi karÄ±ÅŸtÄ±rÄ±lÄ±r ve deÄŸerlendirilmek Ã¼zere hazÄ±rlanÄ±r\n",
    "\n",
    "## Dosya YapÄ±sÄ±:\n",
    "```\n",
    "data/\n",
    "  generated_sentences/\n",
    "    A1/\n",
    "      Llama-3.2-1B-Instruct/\n",
    "        Llama-3.2-1B-Instruct_A1_1.json    â† GROUP_NUMBER = 1\n",
    "        Llama-3.2-1B-Instruct_A1_2.json    â† GROUP_NUMBER = 2\n",
    "      Claude_Sonnet_4.5/\n",
    "        Claude_Sonnet_4.5_A1_1.json\n",
    "        Claude_Sonnet_4.5_A1_2.json\n",
    "      Gemini_Pro_2.5/\n",
    "        Gemini_Pro_2.5_A1_1.json\n",
    "        ...\n",
    "  tasks/\n",
    "    tasks_A1_1.json       â† OluÅŸturulan dosya (direkt tasks altÄ±nda)\n",
    "    tasks_A1_2.json\n",
    "    tasks_B1_1.json\n",
    "    tasks_B2_1.json\n",
    "```\n",
    "\n",
    "## âš ï¸ Ã–nemli:\n",
    "Her model iÃ§in **aynÄ± grup numarasÄ±nda dosya olmalÄ±**. Ã–rneÄŸin Grup 1 iÃ§in:\n",
    "- Llama-3.2-1B-Instruct_A1_1.json âœ…\n",
    "- Claude_Sonnet_4.5_A1_1.json âœ…\n",
    "- Gemini_Pro_2.5_A1_1.json âœ…\n",
    "\n",
    "## Prompt DeÄŸiÅŸiklikleri:\n",
    "- Word Usage kriterine eklendi: \"If the word is not used at all, give the lowest score.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
