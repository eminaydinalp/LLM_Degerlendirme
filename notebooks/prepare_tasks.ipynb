{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863d166-18c1-4a29-ae49-c43121aab666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 görev '/Users/muhammeteminaydinalp/Documents/Master/Tez/Codes/LLM_Degerlendirme/notebooks/../data/tasks/tasks_A1.json' dosyasına kaydedildi.\n",
      "10 görev '/Users/muhammeteminaydinalp/Documents/Master/Tez/Codes/LLM_Degerlendirme/notebooks/../data/tasks/tasks_A2.json' dosyasına kaydedildi.\n",
      "10 görev '/Users/muhammeteminaydinalp/Documents/Master/Tez/Codes/LLM_Degerlendirme/notebooks/../data/tasks/tasks_B1.json' dosyasına kaydedildi.\n",
      "10 görev '/Users/muhammeteminaydinalp/Documents/Master/Tez/Codes/LLM_Degerlendirme/notebooks/../data/tasks/tasks_B2.json' dosyasına kaydedildi.\n",
      "10 görev '/Users/muhammeteminaydinalp/Documents/Master/Tez/Codes/LLM_Degerlendirme/notebooks/../data/tasks/tasks_C1.json' dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================\n",
    "# PARAMETRELER - BURADAN AYARLAYIN\n",
    "# ============================================\n",
    "CEFR_LEVEL = \"A1\"  # \"A1\", \"A2\", \"B1\", \"B2\", \"C1\"\n",
    "GROUP_NUMBER = 1    # 1, 2, 3, ... (kaçıncı grup olduğu)\n",
    "\n",
    "print(f\"🎯 Seviye: {CEFR_LEVEL}\")\n",
    "print(f\"📊 Grup: {GROUP_NUMBER}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dizinleri ayarla\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, \"..\", \"data\", \"generated_sentences\", CEFR_LEVEL)\n",
    "data_dir = os.path.abspath(data_dir)\n",
    "\n",
    "output_base_dir = os.path.join(current_dir, \"..\", \"data\", \"tasks\")\n",
    "output_level_dir = os.path.join(output_base_dir, CEFR_LEVEL)\n",
    "os.makedirs(output_level_dir, exist_ok=True)\n",
    "\n",
    "# Model klasörlerini bul\n",
    "model_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "model_dirs.sort()  # Model1, Model2, Model3, ...\n",
    "\n",
    "print(f\"📁 Bulunan modeller: {model_dirs}\")\n",
    "print(f\"📊 Toplam {len(model_dirs)} model bulundu\")\n",
    "\n",
    "# Her modelden belirtilen grup numarasındaki dosyayı oku\n",
    "grouped_data = defaultdict(list)\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    model_path = os.path.join(data_dir, model_dir)\n",
    "    \n",
    "    # Belirtilen grup numarasındaki dosyayı seç\n",
    "    # Format: Model1_A1_1.json, Model1_A1_2.json, vb.\n",
    "    target_file = f\"{model_dir}_{CEFR_LEVEL}_{GROUP_NUMBER}.json\"\n",
    "    file_path = os.path.join(model_path, target_file)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️  Dosya bulunamadı: {target_file}\")\n",
    "        continue\n",
    "    \n",
    "    # JSON dosyasını oku\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    model_name = data[\"model_name\"]\n",
    "    real_model_name = data.get(\"real_model_name\", model_name)\n",
    "    words = data[\"words\"]\n",
    "    sentences = data[\"sentences\"]\n",
    "    \n",
    "    print(f\"✅ {model_name} ({real_model_name}): {len(words)} kelime\")\n",
    "    \n",
    "    # Her kelime için veriyi grupla\n",
    "    for word, sentence in zip(words, sentences):\n",
    "        grouped_data[word].append({\n",
    "            \"model\": model_name,\n",
    "            \"real_model_name\": real_model_name,\n",
    "            \"sentence\": sentence\n",
    "        })\n",
    "\n",
    "print(f\"\\n📝 Toplam {len(grouped_data)} benzersiz kelime bulundu\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Task'ları oluştur\n",
    "tasks = []\n",
    "\n",
    "# Dinamik label oluştur (model sayısına göre)\n",
    "num_models = len(model_dirs)\n",
    "labels = [f\"Sentence {chr(65+i)}\" for i in range(num_models)]  # A, B, C, D, E, F, ...\n",
    "print(f\"🏷️  Label'lar: {labels}\")\n",
    "\n",
    "# Prompt şablonu - dinamik olarak model sayısını kullan\n",
    "sentences_output_format = \"\\n\".join([f\"{label}: <Word Usage>, <Level Appropriateness>, <Grammar>, <Naturalness>\" for label in labels])\n",
    "\n",
    "prompt_template = \"\"\"You are a professional CEFR-aligned English sentence evaluator.\n",
    "\n",
    "Your task is to evaluate {num_sentences} example sentences that all use the target word: \"{{word}}\" at CEFR level: {{level}}.\n",
    "\n",
    "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
    "\n",
    "1) Word Usage — Is the given word used with the correct meaning and appropriately in context?\n",
    "2) Level Appropriateness — Are the tense, structure, and syntax appropriate for the target CEFR level (A1, A2, B1, B2, C1)?\n",
    "3) Grammatical Accuracy — Are the grammatical structures correct and suitable for the expected level (simple / intermediate / advanced)?\n",
    "4) Naturalness — Does the sentence sound natural and align with standard usage by native English speakers?\n",
    "\n",
    "⚠️ Important Instructions:\n",
    "- **Only return numerical ratings** for each criterion.\n",
    "- **Do not include any explanations, comments, or justifications.**\n",
    "- Follow the exact output format below.\n",
    "\n",
    "### Output Format:\n",
    "{output_format}\n",
    "\n",
    "### Sentences:\n",
    "{{sentences_block}}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = prompt_template.format(\n",
    "    num_sentences=num_models,\n",
    "    output_format=sentences_output_format\n",
    ")\n",
    "\n",
    "for word, sentence_data in grouped_data.items():\n",
    "    if len(sentence_data) != num_models:\n",
    "        print(f\"⚠️  '{word}' için {len(sentence_data)} cümle var ({num_models} gerekli), atlanıyor.\")\n",
    "        continue\n",
    "    \n",
    "    # Cümleleri karıştır\n",
    "    random.shuffle(sentence_data)\n",
    "    \n",
    "    labeled_sentences = []\n",
    "    mapping = {}\n",
    "    sentences_block_lines = []\n",
    "    \n",
    "    for label, item in zip(labels, sentence_data):\n",
    "        sentence = item[\"sentence\"]\n",
    "        labeled_sentences.append((label, sentence))\n",
    "        mapping[label] = {\n",
    "            \"model\": item[\"model\"],\n",
    "            \"real_model_name\": item[\"real_model_name\"],\n",
    "            \"level\": CEFR_LEVEL,\n",
    "            \"word\": word,\n",
    "            \"sentence\": sentence\n",
    "        }\n",
    "        sentences_block_lines.append(f\"{label}: {sentence}\")\n",
    "    \n",
    "    # Promptu oluştur\n",
    "    sentences_block = \"\\n\".join(sentences_block_lines)\n",
    "    prompt = prompt_template.format(\n",
    "        word=word,\n",
    "        level=CEFR_LEVEL,\n",
    "        sentences_block=sentences_block\n",
    "    )\n",
    "    \n",
    "    # Task nesnesi\n",
    "    task = {\n",
    "        \"task_id\": f\"{CEFR_LEVEL}_{word}_{GROUP_NUMBER}\",\n",
    "        \"level\": CEFR_LEVEL,\n",
    "        \"group\": GROUP_NUMBER,\n",
    "        \"word\": word,\n",
    "        \"labeled_sentences\": labeled_sentences,\n",
    "        \"mapping\": mapping,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    \n",
    "    tasks.append(task)\n",
    "\n",
    "# Dosyayı kaydet\n",
    "output_filename = f\"tasks_{CEFR_LEVEL}_{GROUP_NUMBER}.json\"\n",
    "output_filepath = os.path.join(output_level_dir, output_filename)\n",
    "\n",
    "with open(output_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tasks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ {len(tasks)} görev oluşturuldu!\")\n",
    "print(f\"📁 Dosya: {output_filepath}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53680ef-b3d2-4de7-88c3-ca39554625d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📖 Kullanım Kılavuzu\n",
    "\n",
    "## Parametreler:\n",
    "- **CEFR_LEVEL**: Hangi seviye için task oluşturulacak (A1, A2, B1, B2, C1)\n",
    "- **GROUP_NUMBER**: Hangi grup/batch için (1, 2, 3, ...)\n",
    "\n",
    "## Örnek:\n",
    "```python\n",
    "CEFR_LEVEL = \"A1\"\n",
    "GROUP_NUMBER = 1\n",
    "```\n",
    "\n",
    "## Özellikler:\n",
    "- ✅ **Dinamik model sayısı**: Klasörde kaç model varsa hepsini kullanır (5, 6, 7... fark etmez)\n",
    "- ✅ **Otomatik label**: Model sayısına göre A, B, C, D, E, F... oluşturur\n",
    "- ✅ **Yeni dosya formatı**: `Model1_A1_1.json`, `Model1_A1_2.json`, vb.\n",
    "\n",
    "## Çıktı:\n",
    "- **Dosya**: `data/tasks/A1/tasks_A1_1.json`\n",
    "- Her kelime için N model cümlesi karıştırılır ve değerlendirilmek üzere hazırlanır\n",
    "\n",
    "## Dosya Yapısı:\n",
    "```\n",
    "data/\n",
    "  generated_sentences/\n",
    "    A1/\n",
    "      Model1/\n",
    "        Model1_A1_1.json    ← GROUP_NUMBER = 1\n",
    "        Model1_A1_2.json    ← GROUP_NUMBER = 2\n",
    "      Model2/\n",
    "        Model2_A1_1.json\n",
    "        Model2_A1_2.json\n",
    "      Model3/\n",
    "        Model3_A1_1.json\n",
    "        ...\n",
    "  tasks/\n",
    "    A1/\n",
    "      tasks_A1_1.json       ← Oluşturulan dosya\n",
    "      tasks_A1_2.json\n",
    "```\n",
    "\n",
    "## ⚠️ Önemli:\n",
    "Her model için **aynı grup numarasında dosya olmalı**. Örneğin Grup 1 için:\n",
    "- Model1_A1_1.json ✅\n",
    "- Model2_A1_1.json ✅\n",
    "- Model3_A1_1.json ✅\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
