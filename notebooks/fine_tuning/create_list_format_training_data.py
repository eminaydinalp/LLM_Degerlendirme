import json
import random
import sys
import os
from collections import defaultdict

# Komut satÄ±rÄ±ndan dosya adÄ±nÄ± al veya varsayÄ±lan kullan
if len(sys.argv) > 1:
    input_filename = sys.argv[1]
else:
    print("KullanÄ±m: python create_list_format_training_data.py <input_filename>")
    print("Ã–rnek: python create_list_format_training_data.py training_data_b1.json")
    print("\nMevcut dosyalar:")
    data_dir = 'training_data'
    if os.path.exists(data_dir):
        files = [f for f in os.listdir(data_dir) if f.endswith('.json')]
        for f in files:
            print(f"  - {f}")
    input_filename = input("\nHangi dosyayÄ± iÅŸlemek istiyorsunuz? (Ã¶rn: training_data_b1.json): ").strip()

# Dosya yolunu belirle
if os.path.exists(input_filename):
    input_filepath = input_filename
elif os.path.exists(os.path.join('training_data', input_filename)):
    input_filepath = os.path.join('training_data', input_filename)
else:
    print(f"âŒ Hata: '{input_filename}' dosyasÄ± bulunamadÄ±!")
    sys.exit(1)

# Dosya adÄ±ndan seviyeyi Ã§Ä±kar (a1, a2, b1, vb.)
base_filename = os.path.basename(input_filepath)
level = base_filename.replace('training_data_', '').replace('.json', '').upper()

print(f"\nğŸ“‚ Ä°ÅŸleniyor: {input_filepath}")
print(f"ğŸ“Š Seviye: {level}")

# JSON dosyasÄ±nÄ± oku
with open(input_filepath, 'r', encoding='utf-8') as f:
    data = json.load(f)

print(f"Toplam {len(data)} entry bulundu")

# Kelimeleri ve cÃ¼mlelerini grupla
word_sentences = defaultdict(list)

for item in data:
    input_text = item.get('input', '')
    output_text = item.get('output', '')
    
    # Kelimeyi Ã§Ä±kar: "Generate a [LEVEL]-level sentence with [WORD]"
    if 'sentence with ' in input_text:
        word = input_text.split('sentence with ')[-1].strip()
        word_sentences[word].append(output_text)

print(f"Toplam {len(word_sentences)} farklÄ± kelime bulundu")

# FarklÄ± grup boyutlarÄ± iÃ§in training data oluÅŸtur
training_data = []

# Kelimelerin listesini al
all_words = list(word_sentences.keys())

# FarklÄ± stratejiler:
# 1. KÃ¼Ã§Ã¼k gruplar (3-5 kelime) - daha fazla Ã¶rnek
# 2. Orta gruplar (6-8 kelime)
# 3. BÃ¼yÃ¼k gruplar (9-10 kelime) - senin use case'in

def create_group_entry(words_list, group_size):
    """Belirtilen boyutta kelime grubu oluÅŸtur ve cÃ¼mle Ã¼ret"""
    if len(words_list) < group_size:
        return None
    
    # Rastgele kelime seÃ§
    selected_words = random.sample(words_list, group_size)
    
    # Her kelime iÃ§in bir cÃ¼mle seÃ§
    sentences = []
    for i, word in enumerate(selected_words, 1):
        if word_sentences[word]:
            sentence = random.choice(word_sentences[word])
            sentences.append(f"{i}. {sentence}")
    
    # Instruction oluÅŸtur - numaralÄ± liste formatÄ±nda
    numbered_words = "\n".join([f"{i}. {word}" for i, word in enumerate(selected_words, 1)])
    
    entry = {
        "instruction": f"Generate {level}-level English sentences for these {group_size} words:\n{numbered_words}\n\nProvide numbered sentences (1-{group_size}), using each word naturally and appropriately for {level} level.",
        "input": "",
        "output": "\n".join(sentences)
    }
    
    return entry

# Sadece 10 kelime/10 cÃ¼mle formatÄ±nda Ã¶rnekler oluÅŸtur
random.seed(42)  # Tekrarlanabilirlik iÃ§in

num_examples = 2000  # Toplam Ã¶rnek sayÄ±sÄ±
group_size = 10  # Sabit: 10 kelime/10 cÃ¼mle

print(f"\nğŸ¯ {num_examples} adet 10 kelime/10 cÃ¼mle Ã¶rneÄŸi oluÅŸturuluyor...")

for _ in range(num_examples):
    entry = create_group_entry(all_words, group_size)
    if entry:
        training_data.append(entry)

# Veriyi karÄ±ÅŸtÄ±r
random.shuffle(training_data)

print(f"âœ“ Toplam {len(training_data)} Ã¶rnek oluÅŸturuldu (tÃ¼mÃ¼ 10 kelime/10 cÃ¼mle formatÄ±nda)")

# Train/Eval split yap (%90 / %10)
train_ratio = 0.9
split_index = int(len(training_data) * train_ratio)

train_data = training_data[:split_index]
eval_data = training_data[split_index:]

print(f"\nğŸ“Š Train/Eval Split:")
print(f"  - Train: {len(train_data)} Ã¶rnekler (%{train_ratio*100:.0f})")
print(f"  - Eval:  {len(eval_data)} Ã¶rnekler (%{(1-train_ratio)*100:.0f})")

# Ã‡Ä±ktÄ± dosya adlarÄ±nÄ± oluÅŸtur
output_train_json = f'training_data_{level.lower()}_list_format_train.json'
output_eval_json = f'training_data_{level.lower()}_list_format_eval.json'

# JSON formatÄ±nda kaydet (Train)
with open(output_train_json, 'w', encoding='utf-8') as f:
    json.dump(train_data, f, indent=2, ensure_ascii=False)

# JSON formatÄ±nda kaydet (Eval)
with open(output_eval_json, 'w', encoding='utf-8') as f:
    json.dump(eval_data, f, indent=2, ensure_ascii=False)

print(f"\nâœ“ Train JSON kaydedildi: {output_train_json}")
print(f"âœ“ Eval JSON kaydedildi:  {output_eval_json}")

# Ã–rnek gÃ¶ster
print("\n" + "="*60)
print("Ä°LK 3 TRAIN Ã–RNEÄÄ°:")
print("="*60)
for i in range(min(3, len(train_data))):
    print(f"\n--- Ã–rnek {i+1} ---")
    print(f"Instruction: {train_data[i]['instruction']}")
    print(f"Response:\n{train_data[i]['output']}")
    print()
