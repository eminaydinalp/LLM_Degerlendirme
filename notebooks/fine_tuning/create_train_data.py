import os
import csv
import json
import time
from openai import OpenAI
from dotenv import load_dotenv

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# OpenAI client'Ä± baÅŸlat
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ============================================
# BURADAN SEVÄ°YE SEÃ‡Ä°MÄ° YAPIN
# ============================================
CEFR_LEVEL = "B2"  # "A1", "A2", "B1", "B2", "C1" seÃ§eneklerinden birini yazÄ±n

print(f"ðŸŽ¯ SeÃ§ilen CEFR Seviyesi: {CEFR_LEVEL}")
print(f"ðŸ“ Kelime dosyasÄ±: {CEFR_LEVEL}_words.csv")
print(f"ðŸ’¾ Ã‡Ä±ktÄ± dosyasÄ±: training_data_{CEFR_LEVEL.lower()}.json")
print("-" * 60)

# Dosya yollarÄ±
current_dir = os.path.dirname(os.path.abspath(__file__))
words_file = os.path.join(current_dir, "words", f"{CEFR_LEVEL}_words.csv")

# training_data klasÃ¶rÃ¼nÃ¼ oluÅŸtur (yoksa)
output_dir = os.path.join(current_dir, "training_data")
os.makedirs(output_dir, exist_ok=True)

output_file = os.path.join(output_dir, f"training_data_{CEFR_LEVEL.lower()}.json")

# Kelimeleri oku
words = []
with open(words_file, "r", encoding="utf-8") as f:
    reader = csv.DictReader(f)
    for row in reader:
        words.append(row["Words"].strip())

# TEST Ä°Ã‡Ä°N SADECE Ä°LK 3 KELÄ°ME
TEST_MODE = False  # TÃ¼m kelimeler iÃ§in False yapÄ±n
if TEST_MODE:
    words = words[:3]
    print(f"âš ï¸ TEST MODU: Sadece ilk {len(words)} kelime kullanÄ±lÄ±yor")
else:
    print(f"{len(words)} kelime okundu.")

# Mevcut dosyayÄ± oku (eÄŸer varsa) - kaldÄ±ÄŸÄ± yerden devam etmek iÃ§in
training_data = []
processed_words = set()
if os.path.exists(output_file):
    try:
        with open(output_file, "r", encoding="utf-8") as f:
            training_data = json.load(f)
            # Hangi kelimeler iÅŸlenmiÅŸ bul
            for item in training_data:
                # "Generate a A1-level sentence with word" formatÄ±ndan kelimeyi Ã§Ä±kar
                word_from_input = item["input"].split("with ")[-1].strip()
                processed_words.add(word_from_input)
        print(f"âœ… Mevcut dosyada {len(training_data)} cÃ¼mle bulundu ({len(processed_words)} kelime iÅŸlenmiÅŸ)")
        print(f"ðŸ“ KaldÄ±ÄŸÄ± yerden devam ediliyor...\n")
    except:
        print("âš ï¸ Mevcut dosya okunamadÄ±, baÅŸtan baÅŸlanÄ±yor...\n")
else:
    print("ðŸ“ Yeni dosya oluÅŸturuluyor...\n")

SENTENCES_PER_WORD = 5  # Her kelime iÃ§in 5 farklÄ± cÃ¼mle

for i, word in enumerate(words, 1):
    # EÄŸer bu kelime zaten iÅŸlenmiÅŸse atla
    if word in processed_words:
        continue
        
    print(f"[{i}/{len(words)}] '{word}' iÃ§in {SENTENCES_PER_WORD} cÃ¼mle oluÅŸturuluyor...")
    
    generated_sentences = set()  # Tekrar kontrolÃ¼ iÃ§in
    attempts = 0
    max_attempts = 10  # Her cÃ¼mle iÃ§in maksimum deneme sayÄ±sÄ± (15->20)
    
    j = 0
    while j < SENTENCES_PER_WORD and attempts < max_attempts:
        attempts += 1
        try:
            # Ã–nceki cÃ¼mleleri gÃ¶ster (tekrarÄ± Ã¶nlemek iÃ§in)
            previous_sentences = ""
            if generated_sentences:
                prev_list = "\n".join([f"- {s}" for s in generated_sentences])
                previous_sentences = f"\n\nPreviously generated sentences:\n{prev_list}\n\nIMPORTANT: Create a COMPLETELY DIFFERENT sentence. Use different sentence structure, grammar pattern, and context. Don't just change the nouns - change how you use the word."
            
            # ChatGPT'ye prompt gÃ¶nder
            prompt = f"""Generate a natural {CEFR_LEVEL}-level English sentence using the word "{word}".{previous_sentences}

Return ONLY a valid JSON object in this exact format (no additional text):
{{
    "input": "Generate a {CEFR_LEVEL}-level sentence with {word}",
    "output": "your generated sentence here"
}}"""

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"""You are an expert English teacher. Create natural, meaningful sentences at CEFR {CEFR_LEVEL} level.

Requirements:
- Use the word correctly with appropriate meaning for {CEFR_LEVEL} level
- Use grammar and vocabulary suitable for {CEFR_LEVEL} level
- Make it natural and realistic

Return only valid JSON."""},
                    {"role": "user", "content": prompt}
                ],
                temperature=1.0,
                max_tokens=150
            )
            
            # YanÄ±tÄ± al ve parse et
            content = response.choices[0].message.content.strip()
            
            # JSON parse et
            try:
                # EÄŸer markdown code block iÃ§indeyse temizle
                if content.startswith("```"):
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:].strip()
                
                data = json.loads(content)
                sentence = data['output'].strip()
                
                # Tekrar kontrolÃ¼ - aynÄ± cÃ¼mle daha Ã¶nce oluÅŸturulmamÄ±ÅŸsa ekle
                if sentence not in generated_sentences:
                    generated_sentences.add(sentence)
                    training_data.append(data)
                    
                    # ANLIK KAYDET - Her cÃ¼mle eklendikÃ§e dosyaya yaz
                    with open(output_file, "w", encoding="utf-8") as f:
                        json.dump(training_data, f, ensure_ascii=False, indent=2)
                    
                    j += 1
                    print(f"  [{j}/{SENTENCES_PER_WORD}] âœ“ {sentence[:60]}...")
                else:
                    print(f"  [!] Tekrar atlandÄ±: {sentence[:60]}...")
                
            except json.JSONDecodeError as e:
                print(f"  âœ— JSON parse hatasÄ±: {e}")
                print(f"  Ä°Ã§erik: {content}")
            
            # Rate limit iÃ§in bekleme
            time.sleep(0.5)
            
        except Exception as e:
            print(f"  âœ— Hata: {e}")
            continue
    
    # EÄŸer 5 benzersiz cÃ¼mle oluÅŸturulamazsa uyarÄ± ver
    if j < SENTENCES_PER_WORD:
        print(f"  âš ï¸ Sadece {j}/{SENTENCES_PER_WORD} benzersiz cÃ¼mle oluÅŸturulabildi.")

# Son kontrol - dosyaya tekrar yaz (gÃ¼venlik iÃ§in)
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(training_data, f, ensure_ascii=False, indent=2)

print(f"\nâœ… TamamlandÄ±! {len(training_data)} veri '{output_file}' dosyasÄ±na kaydedildi.")
