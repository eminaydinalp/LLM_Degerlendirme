{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2257c50-a887-4b2f-83d8-2e468931efa3",
   "metadata": {},
   "source": [
    "# Tek Bir JSON Dosyasƒ±ndan Veri √áekelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf1138f-5d3b-42be-b7b3-85ecc15463d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'age', 'sentence': 'My birthday is on January 12th.'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'animal', 'sentence': 'The cat is a pet animal.'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'ask', 'sentence': 'Can you ask your teacher for help?'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'computer', 'sentence': 'The computer is very useful for students.'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'eat', 'sentence': 'I like to eat pizza on Fridays.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# √ñrnek dosya yolu\n",
    "file_path = \"Model2.json\"\n",
    "\n",
    "# JSON dosyasƒ±nƒ± oku\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "entries = []\n",
    "\n",
    "model_name = data[\"model_name\"]\n",
    "\n",
    "for generation in data[\"generations\"]:\n",
    "    level = generation[\"cefr_level\"]\n",
    "    words = generation[\"word_list\"]\n",
    "    sentences = generation[\"generated_sentences\"]\n",
    "\n",
    "    for word, sentence in zip(words, sentences):\n",
    "        entries.append({\n",
    "            \"model\": model_name,\n",
    "            \"level\": level,\n",
    "            \"word\": word,\n",
    "            \"sentence\": sentence\n",
    "        })\n",
    "\n",
    "# Kontrol ama√ßlƒ± ilk birka√ß girdiyi yazdƒ±ralƒ±m\n",
    "for e in entries[:5]:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7433be-4471-4de7-a743-1d2cb44002b0",
   "metadata": {},
   "source": [
    "# √áoklu Dosyadan Veriyi Al, Etiketle, Karƒ±≈ütƒ±r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620a32f9-a996-48e9-80e6-b9f6985599de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample task for word 'age' (Level: A1)\n",
      "\n",
      "Sentence A: I am ten years old.\n",
      "Sentence B: My birthday is on January 12th.\n",
      "Sentence C: I am 20 years old.\n",
      "Sentence D: My age is twenty-five years old.\n",
      "Sentence E: My age is seven years old.\n",
      "Sentence F: I am 10 years old, and I love playing with my pet dog.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# üìÅ JSON dosyalarƒ±nƒ±n bulunduƒüu klas√∂r\n",
    "json_folder = \"data/model_results\"\n",
    "\n",
    "# üíæ T√ºm c√ºmleleri saklayacaƒüƒ±mƒ±z yer\n",
    "all_entries = []\n",
    "\n",
    "# üì• T√ºm dosyalarƒ± oku\n",
    "for filename in os.listdir(json_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(json_folder, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            model_name = data[\"model_name\"]\n",
    "            for generation in data[\"generations\"]:\n",
    "                level = generation[\"cefr_level\"]\n",
    "                words = generation[\"word_list\"]\n",
    "                sentences = generation[\"generated_sentences\"]\n",
    "                for word, sentence in zip(words, sentences):\n",
    "                    all_entries.append({\n",
    "                        \"model\": model_name,\n",
    "                        \"level\": level,\n",
    "                        \"word\": word,\n",
    "                        \"sentence\": sentence\n",
    "                    })\n",
    "\n",
    "# ‚úÖ Her kelime i√ßin 6 modelin c√ºmlesini gruplama\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "for entry in all_entries:\n",
    "    key = (entry[\"level\"], entry[\"word\"])  # √∂rnek: (\"A1\", \"age\")\n",
    "    grouped[key].append(entry)\n",
    "\n",
    "# ‚úÖ C√ºmleleri karƒ±≈ütƒ±r, etiketle ve mapping olu≈ütur\n",
    "all_tasks = []\n",
    "\n",
    "for (level, word), sentence_group in grouped.items():\n",
    "    if len(sentence_group) != 6:\n",
    "        print(f\"Uyarƒ±: {level} seviyesinde '{word}' kelimesi i√ßin {len(sentence_group)} c√ºmle var. Atlanƒ±yor.\")\n",
    "        continue\n",
    "\n",
    "    # C√ºmleleri karƒ±≈ütƒ±r\n",
    "    random.shuffle(sentence_group)\n",
    "\n",
    "    labels = [\"Sentence A\", \"Sentence B\", \"Sentence C\", \"Sentence D\", \"Sentence E\", \"Sentence F\"]\n",
    "\n",
    "    labeled_sentences = []\n",
    "    mapping = {}\n",
    "\n",
    "    for label, item in zip(labels, sentence_group):\n",
    "        labeled_sentences.append((label, item[\"sentence\"]))\n",
    "        mapping[label] = {\n",
    "            \"model\": item[\"model\"],\n",
    "            \"level\": level,\n",
    "            \"word\": word,\n",
    "            \"sentence\": item[\"sentence\"]\n",
    "        }\n",
    "\n",
    "    all_tasks.append({\n",
    "        \"level\": level,\n",
    "        \"word\": word,\n",
    "        \"labeled_sentences\": labeled_sentences,\n",
    "        \"mapping\": mapping\n",
    "    })\n",
    "\n",
    "# üîç √ñrnek √ßƒ±ktƒ± (bir task)\n",
    "example = all_tasks[0]\n",
    "print(f\"\\nSample task for word '{example['word']}' (Level: {example['level']})\\n\")\n",
    "for label, sentence in example[\"labeled_sentences\"]:\n",
    "    print(f\"{label}: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85bd2f-624d-4ac2-9c28-48f0b42d15a4",
   "metadata": {},
   "source": [
    "# Promptlarƒ± Otomatik √úretmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b44c9c7-dd61-42c4-9c66-729c47379387",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompts = []\n",
    "\n",
    "prompt_template = \"\"\"You are a professional CEFR-aligned English sentence evaluator.\n",
    "\n",
    "Your task is to evaluate 6 example sentences that all use the target word: \"{word}\" at CEFR level: {level}.\n",
    "\n",
    "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
    "\n",
    "1. **Word Usage** ‚Äì Is the target word used correctly and meaningfully in context?\n",
    "2. **Clarity** ‚Äì Is the sentence understandable and suitable for the given CEFR level?\n",
    "3. **Grammar** ‚Äì Is the grammar accurate and appropriate for the level?\n",
    "4. **Naturalness** ‚Äì Does the sentence sound fluent and natural to a native speaker?\n",
    "\n",
    "‚ö†Ô∏è Important Instructions:\n",
    "- **Only return numerical ratings** for each criterion.\n",
    "- **Do not include any explanations, comments, or justifications.**\n",
    "- Follow the exact output format below.\n",
    "\n",
    "### Output Format:\n",
    "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \n",
    "Sentence B: ...  \n",
    "Sentence C: ...  \n",
    "Sentence D: ...  \n",
    "Sentence E: ...  \n",
    "Sentence F: ...  \n",
    "\n",
    "### Sentences:\n",
    "Sentence A: {sentence_A}  \n",
    "Sentence B: {sentence_B}  \n",
    "Sentence C: {sentence_C}  \n",
    "Sentence D: {sentence_D}  \n",
    "Sentence E: {sentence_E}  \n",
    "Sentence F: {sentence_F}\n",
    "\"\"\"\n",
    "\n",
    "for task in all_tasks:\n",
    "    word = task[\"word\"]\n",
    "    level = task[\"level\"]\n",
    "    labeled = dict(task[\"labeled_sentences\"])  # {'Sentence A': '...', ...}\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        word=word,\n",
    "        level=level,\n",
    "        sentence_A=labeled[\"Sentence A\"],\n",
    "        sentence_B=labeled[\"Sentence B\"],\n",
    "        sentence_C=labeled[\"Sentence C\"],\n",
    "        sentence_D=labeled[\"Sentence D\"],\n",
    "        sentence_E=labeled[\"Sentence E\"],\n",
    "        sentence_F=labeled[\"Sentence F\"],\n",
    "    )\n",
    "\n",
    "    # Prompt'la birlikte task ID'sini (level, word) saklƒ±yoruz\n",
    "    task_prompts.append({\n",
    "        \"level\": level,\n",
    "        \"word\": word,\n",
    "        \"prompt\": prompt\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e2e213-ebea-4f09-a16a-aba7183aeda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç First Prompt Preview:\n",
      "\n",
      "You are an expert English evaluator.\n",
      "\n",
      "Evaluate the following 6 example sentences that all use the word: \"religion\" (CEFR Level: B1).\n",
      "\n",
      "Rate each sentence from 1 (poor) to 5 (excellent) on the following four criteria:\n",
      "\n",
      "1. Word Usage ‚Äì Is the word used correctly and meaningfully?\n",
      "2. Clarity ‚Äì Is the sentence understandable and appropriate for the given CEFR level?\n",
      "3. Grammar ‚Äì Is the grammar correct and level-appropriate?\n",
      "4. Naturalness ‚Äì Does the sentence sound natural and fluent (not AI-generated)?\n",
      "\n",
      "‚ö†Ô∏è Do not give any explanations or comments.\n",
      "‚ö†Ô∏è Just return the ratings in the following format, with no extra output:\n",
      "\n",
      "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>\n",
      "Sentence B: ...\n",
      "Sentence C: ...\n",
      "Sentence D: ...\n",
      "Sentence E: ...\n",
      "Sentence F: ...\n",
      "\n",
      "Sentences:\n",
      "Sentence A: People should respect each other's religion.\n",
      "Sentence B: The new employee has to respect the company's religion policy.\n",
      "Sentence C: Different cultures have their own religion and traditions.\n",
      "Sentence D: Different cultures practice different forms of religion.\n",
      "Sentence E: Her religion is important to her.\n",
      "Sentence F: The religion of Buddhism emphasizes the importance of meditation and compassion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç First Prompt Preview:\\n\")\n",
    "print(task_prompts[27][\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8558ff-0948-4aa3-a81f-5028d92138ad",
   "metadata": {},
   "source": [
    "# DeepSeek ile 2 Prompt Testi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19ee3b7-a696-4bf8-808a-9fc8c2971924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prompt 1 (age, A1) ---\n",
      "\n",
      "üü¶ Raw Output:\n",
      " Sentence A: 5, 5, 5, 5  \n",
      "Sentence B: 1, 5, 5, 5  \n",
      "Sentence C: 5, 5, 5, 5  \n",
      "Sentence D: 3, 4, 3, 3  \n",
      "Sentence E: 3, 4, 3, 3  \n",
      "Sentence F: 5, 5, 5, 5\n",
      "\n",
      "‚úÖ Parsed Scores:\n",
      "Sentence A: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence B: {'Word Usage': 1, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence C: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence D: {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3}\n",
      "Sentence E: {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3}\n",
      "Sentence F: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "\n",
      "--- Prompt 2 (animal, A1) ---\n",
      "\n",
      "üü¶ Raw Output:\n",
      " Sentence A: 4, 4, 5, 5  \n",
      "Sentence B: 5, 5, 5, 5  \n",
      "Sentence C: 5, 5, 5, 5  \n",
      "Sentence D: 5, 5, 5, 5  \n",
      "Sentence E: 4, 4, 5, 4  \n",
      "Sentence F: 5, 5, 5, 5\n",
      "\n",
      "‚úÖ Parsed Scores:\n",
      "Sentence A: {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence B: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence C: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence D: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence E: {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 4}\n",
      "Sentence F: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# DeepSeek API key ve base_url\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-9115f967efad41a09f30b761d5f36f53\",\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "# ƒ∞lk iki prompt (daha √∂nce tanƒ±mladƒ±ƒüƒ±n task_prompts listesi)\n",
    "prompts_to_test = task_prompts[:2]\n",
    "\n",
    "def parse_scores(raw_response):\n",
    "    parsed = {}\n",
    "    lines = raw_response.strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            parts = line.split(\":\")\n",
    "            label = parts[0].strip()\n",
    "            scores = [int(s.strip()) for s in parts[1].split(\",\") if s.strip().isdigit()]\n",
    "            if len(scores) == 4:\n",
    "                parsed[label] = {\n",
    "                    \"Word Usage\": scores[0],\n",
    "                    \"Clarity\": scores[1],\n",
    "                    \"Grammar\": scores[2],\n",
    "                    \"Naturalness\": scores[3]\n",
    "                }\n",
    "    return parsed\n",
    "\n",
    "# Test et\n",
    "for i, task in enumerate(prompts_to_test):\n",
    "    print(f\"\\n--- Prompt {i+1} ({task['word']}, {task['level']}) ---\\n\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": task[\"prompt\"]}\n",
    "            ],\n",
    "            temperature=1.0\n",
    "        )\n",
    "\n",
    "        raw_output = response.choices[0].message.content\n",
    "        print(\"üü¶ Raw Output:\\n\", raw_output)\n",
    "\n",
    "        parsed = parse_scores(raw_output)\n",
    "        print(\"\\n‚úÖ Parsed Scores:\")\n",
    "        for sentence, scores in parsed.items():\n",
    "            print(f\"{sentence}: {scores}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Hata:\", e)\n",
    "\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c65bbbe-bf31-48d2-8c17-e66cc0036f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Model: GPT-4-turbo\n",
      "  üîπ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [5] ‚Üí Avg: 5.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "  üîπ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] ‚Üí Avg: 5.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "\n",
      "üß† Model: Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf\n",
      "  üîπ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [1] ‚Üí Avg: 1.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "  üîπ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [4] ‚Üí Avg: 4.0\n",
      "    - Clarity: [4] ‚Üí Avg: 4.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "\n",
      "üß† Model: Ministral-8B-Instruct-2410.Q4_K_M.gguf\n",
      "  üîπ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [5] ‚Üí Avg: 5.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "  üîπ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] ‚Üí Avg: 5.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "\n",
      "üß† Model: Claude Sonnet 4\n",
      "  üîπ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [3] ‚Üí Avg: 3.0\n",
      "    - Clarity: [4] ‚Üí Avg: 4.0\n",
      "    - Grammar: [3] ‚Üí Avg: 3.0\n",
      "    - Naturalness: [3] ‚Üí Avg: 3.0\n",
      "  üîπ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [4] ‚Üí Avg: 4.0\n",
      "    - Clarity: [4] ‚Üí Avg: 4.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [4] ‚Üí Avg: 4.0\n",
      "\n",
      "üß† Model: Gemini 2.5 Flash\n",
      "  üîπ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [3] ‚Üí Avg: 3.0\n",
      "    - Clarity: [4] ‚Üí Avg: 4.0\n",
      "    - Grammar: [3] ‚Üí Avg: 3.0\n",
      "    - Naturalness: [3] ‚Üí Avg: 3.0\n",
      "  üîπ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] ‚Üí Avg: 5.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "\n",
      "üß† Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf\n",
      "  üîπ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [5] ‚Üí Avg: 5.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n",
      "  üîπ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] ‚Üí Avg: 5.0\n",
      "    - Clarity: [5] ‚Üí Avg: 5.0\n",
      "    - Grammar: [5] ‚Üí Avg: 5.0\n",
      "    - Naturalness: [5] ‚Üí Avg: 5.0\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ √ñnce DeepSeek'ten d√∂nen raw skorlarƒ± hardcoded ≈üekilde ekleyelim:\n",
    "\n",
    "deepseek_results = {\n",
    "    (\"A1\", \"age\"): {\n",
    "        \"Sentence A\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence B\": {'Word Usage': 1, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence C\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence D\": {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3},\n",
    "        \"Sentence E\": {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3},\n",
    "        \"Sentence F\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "    },\n",
    "    (\"A1\", \"animal\"): {\n",
    "        \"Sentence A\": {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence B\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence C\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence D\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence E\": {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 4},\n",
    "        \"Sentence F\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "    }\n",
    "}\n",
    "\n",
    "# ‚úÖ Model bazlƒ± puanlarƒ± toplayacaƒüƒ±mƒ±z dict\n",
    "model_scores = {}\n",
    "\n",
    "# ‚úÖ all_tasks i√ßinden ilgili kelimeleri bul\n",
    "for task in all_tasks:\n",
    "    key = (task[\"level\"], task[\"word\"])\n",
    "    if key not in deepseek_results:\n",
    "        continue\n",
    "\n",
    "    scores_for_task = deepseek_results[key]\n",
    "    mapping = task[\"mapping\"]\n",
    "\n",
    "    for sentence_label, scores in scores_for_task.items():\n",
    "        model_name = mapping[sentence_label][\"model\"]\n",
    "\n",
    "        if model_name not in model_scores:\n",
    "            model_scores[model_name] = {}\n",
    "\n",
    "        if key not in model_scores[model_name]:\n",
    "            model_scores[model_name][key] = {\n",
    "                \"Word Usage\": [],\n",
    "                \"Clarity\": [],\n",
    "                \"Grammar\": [],\n",
    "                \"Naturalness\": []\n",
    "            }\n",
    "\n",
    "        # Skorlarƒ± ekle\n",
    "        for criterion, value in scores.items():\n",
    "            model_scores[model_name][key][criterion].append(value)\n",
    "\n",
    "# ‚úÖ Sonu√ßlarƒ± yazdƒ±r\n",
    "for model, words in model_scores.items():\n",
    "    print(f\"\\nüß† Model: {model}\")\n",
    "    for (level, word), criteria in words.items():\n",
    "        print(f\"  üîπ Word: '{word}' (Level: {level})\")\n",
    "        for criterion, values in criteria.items():\n",
    "            avg = round(sum(values) / len(values), 2)\n",
    "            print(f\"    - {criterion}: {values} ‚Üí Avg: {avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e2c9d7-4c25-4c12-a597-85414c273ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Mapping for 'age' (A1)\n",
      "Sentence A ‚Üí GPT-4-turbo\n",
      "Sentence B ‚Üí Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf\n",
      "Sentence C ‚Üí Ministral-8B-Instruct-2410.Q4_K_M.gguf\n",
      "Sentence D ‚Üí Claude Sonnet 4\n",
      "Sentence E ‚Üí Gemini 2.5 Flash\n",
      "Sentence F ‚Üí Llama-3.2-3B-Instruct-Q4_K_M.gguf\n",
      "\n",
      "üìå Mapping for 'animal' (A1)\n",
      "Sentence A ‚Üí Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf\n",
      "Sentence B ‚Üí Ministral-8B-Instruct-2410.Q4_K_M.gguf\n",
      "Sentence C ‚Üí Llama-3.2-3B-Instruct-Q4_K_M.gguf\n",
      "Sentence D ‚Üí Gemini 2.5 Flash\n",
      "Sentence E ‚Üí Claude Sonnet 4\n",
      "Sentence F ‚Üí GPT-4-turbo\n"
     ]
    }
   ],
   "source": [
    "# Age ve animal kelimeleri i√ßin mapping'leri yazdƒ±ralƒ±m\n",
    "for task in all_tasks:\n",
    "    if (task[\"level\"], task[\"word\"]) in [(\"A1\", \"age\"), (\"A1\", \"animal\")]:\n",
    "        print(f\"\\nüìå Mapping for '{task['word']}' ({task['level']})\")\n",
    "        for label, info in task[\"mapping\"].items():\n",
    "            print(f\"{label} ‚Üí {info['model']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7feaa5-8613-437c-a874-9622178f7eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
