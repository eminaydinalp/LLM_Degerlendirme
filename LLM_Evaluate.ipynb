{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2257c50-a887-4b2f-83d8-2e468931efa3",
   "metadata": {},
   "source": [
    "# Tek Bir JSON DosyasÄ±ndan Veri Ã‡ekelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf1138f-5d3b-42be-b7b3-85ecc15463d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'age', 'sentence': 'My birthday is on January 12th.'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'animal', 'sentence': 'The cat is a pet animal.'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'ask', 'sentence': 'Can you ask your teacher for help?'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'computer', 'sentence': 'The computer is very useful for students.'}\n",
      "{'model': 'Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf', 'level': 'A1', 'word': 'eat', 'sentence': 'I like to eat pizza on Fridays.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ã–rnek dosya yolu\n",
    "file_path = \"Model2.json\"\n",
    "\n",
    "# JSON dosyasÄ±nÄ± oku\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "entries = []\n",
    "\n",
    "model_name = data[\"model_name\"]\n",
    "\n",
    "for generation in data[\"generations\"]:\n",
    "    level = generation[\"cefr_level\"]\n",
    "    words = generation[\"word_list\"]\n",
    "    sentences = generation[\"generated_sentences\"]\n",
    "\n",
    "    for word, sentence in zip(words, sentences):\n",
    "        entries.append({\n",
    "            \"model\": model_name,\n",
    "            \"level\": level,\n",
    "            \"word\": word,\n",
    "            \"sentence\": sentence\n",
    "        })\n",
    "\n",
    "# Kontrol amaÃ§lÄ± ilk birkaÃ§ girdiyi yazdÄ±ralÄ±m\n",
    "for e in entries[:5]:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7433be-4471-4de7-a743-1d2cb44002b0",
   "metadata": {},
   "source": [
    "# Ã‡oklu Dosyadan Veriyi Al, Etiketle, KarÄ±ÅŸtÄ±r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620a32f9-a996-48e9-80e6-b9f6985599de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample task for word 'age' (Level: A1)\n",
      "\n",
      "Sentence A: I am ten years old.\n",
      "Sentence B: My birthday is on January 12th.\n",
      "Sentence C: I am 20 years old.\n",
      "Sentence D: My age is twenty-five years old.\n",
      "Sentence E: My age is seven years old.\n",
      "Sentence F: I am 10 years old, and I love playing with my pet dog.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# ğŸ“ JSON dosyalarÄ±nÄ±n bulunduÄŸu klasÃ¶r\n",
    "json_folder = \"data/model_results\"\n",
    "\n",
    "# ğŸ’¾ TÃ¼m cÃ¼mleleri saklayacaÄŸÄ±mÄ±z yer\n",
    "all_entries = []\n",
    "\n",
    "# ğŸ“¥ TÃ¼m dosyalarÄ± oku\n",
    "for filename in os.listdir(json_folder):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(json_folder, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            model_name = data[\"model_name\"]\n",
    "            for generation in data[\"generations\"]:\n",
    "                level = generation[\"cefr_level\"]\n",
    "                words = generation[\"word_list\"]\n",
    "                sentences = generation[\"generated_sentences\"]\n",
    "                for word, sentence in zip(words, sentences):\n",
    "                    all_entries.append({\n",
    "                        \"model\": model_name,\n",
    "                        \"level\": level,\n",
    "                        \"word\": word,\n",
    "                        \"sentence\": sentence\n",
    "                    })\n",
    "\n",
    "# âœ… Her kelime iÃ§in 6 modelin cÃ¼mlesini gruplama\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "for entry in all_entries:\n",
    "    key = (entry[\"level\"], entry[\"word\"])  # Ã¶rnek: (\"A1\", \"age\")\n",
    "    grouped[key].append(entry)\n",
    "\n",
    "# âœ… CÃ¼mleleri karÄ±ÅŸtÄ±r, etiketle ve mapping oluÅŸtur\n",
    "all_tasks = []\n",
    "\n",
    "for (level, word), sentence_group in grouped.items():\n",
    "    if len(sentence_group) != 6:\n",
    "        print(f\"UyarÄ±: {level} seviyesinde '{word}' kelimesi iÃ§in {len(sentence_group)} cÃ¼mle var. AtlanÄ±yor.\")\n",
    "        continue\n",
    "\n",
    "    # CÃ¼mleleri karÄ±ÅŸtÄ±r\n",
    "    random.shuffle(sentence_group)\n",
    "\n",
    "    labels = [\"Sentence A\", \"Sentence B\", \"Sentence C\", \"Sentence D\", \"Sentence E\", \"Sentence F\"]\n",
    "\n",
    "    labeled_sentences = []\n",
    "    mapping = {}\n",
    "\n",
    "    for label, item in zip(labels, sentence_group):\n",
    "        labeled_sentences.append((label, item[\"sentence\"]))\n",
    "        mapping[label] = {\n",
    "            \"model\": item[\"model\"],\n",
    "            \"level\": level,\n",
    "            \"word\": word,\n",
    "            \"sentence\": item[\"sentence\"]\n",
    "        }\n",
    "\n",
    "    all_tasks.append({\n",
    "        \"level\": level,\n",
    "        \"word\": word,\n",
    "        \"labeled_sentences\": labeled_sentences,\n",
    "        \"mapping\": mapping\n",
    "    })\n",
    "\n",
    "# ğŸ” Ã–rnek Ã§Ä±ktÄ± (bir task)\n",
    "example = all_tasks[0]\n",
    "print(f\"\\nSample task for word '{example['word']}' (Level: {example['level']})\\n\")\n",
    "for label, sentence in example[\"labeled_sentences\"]:\n",
    "    print(f\"{label}: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85bd2f-624d-4ac2-9c28-48f0b42d15a4",
   "metadata": {},
   "source": [
    "# PromptlarÄ± Otomatik Ãœretmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b44c9c7-dd61-42c4-9c66-729c47379387",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompts = []\n",
    "\n",
    "prompt_template = \"\"\"You are a professional CEFR-aligned English sentence evaluator.\n",
    "\n",
    "Your task is to evaluate 6 example sentences that all use the target word: \"{word}\" at CEFR level: {level}.\n",
    "\n",
    "Rate each sentence from 1 (poor) to 5 (excellent) for the following **four independent criteria**:\n",
    "\n",
    "1. **Word Usage** â€“ Is the target word used correctly and meaningfully in context?\n",
    "2. **Clarity** â€“ Is the sentence understandable and suitable for the given CEFR level?\n",
    "3. **Grammar** â€“ Is the grammar accurate and appropriate for the level?\n",
    "4. **Naturalness** â€“ Does the sentence sound fluent and natural to a native speaker?\n",
    "\n",
    "âš ï¸ Important Instructions:\n",
    "- **Only return numerical ratings** for each criterion.\n",
    "- **Do not include any explanations, comments, or justifications.**\n",
    "- Follow the exact output format below.\n",
    "\n",
    "### Output Format:\n",
    "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>  \n",
    "Sentence B: ...  \n",
    "Sentence C: ...  \n",
    "Sentence D: ...  \n",
    "Sentence E: ...  \n",
    "Sentence F: ...  \n",
    "\n",
    "### Sentences:\n",
    "Sentence A: {sentence_A}  \n",
    "Sentence B: {sentence_B}  \n",
    "Sentence C: {sentence_C}  \n",
    "Sentence D: {sentence_D}  \n",
    "Sentence E: {sentence_E}  \n",
    "Sentence F: {sentence_F}\n",
    "\"\"\"\n",
    "\n",
    "for task in all_tasks:\n",
    "    word = task[\"word\"]\n",
    "    level = task[\"level\"]\n",
    "    labeled = dict(task[\"labeled_sentences\"])  # {'Sentence A': '...', ...}\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        word=word,\n",
    "        level=level,\n",
    "        sentence_A=labeled[\"Sentence A\"],\n",
    "        sentence_B=labeled[\"Sentence B\"],\n",
    "        sentence_C=labeled[\"Sentence C\"],\n",
    "        sentence_D=labeled[\"Sentence D\"],\n",
    "        sentence_E=labeled[\"Sentence E\"],\n",
    "        sentence_F=labeled[\"Sentence F\"],\n",
    "    )\n",
    "\n",
    "    # Prompt'la birlikte task ID'sini (level, word) saklÄ±yoruz\n",
    "    task_prompts.append({\n",
    "        \"level\": level,\n",
    "        \"word\": word,\n",
    "        \"prompt\": prompt\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e2e213-ebea-4f09-a16a-aba7183aeda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” First Prompt Preview:\n",
      "\n",
      "You are an expert English evaluator.\n",
      "\n",
      "Evaluate the following 6 example sentences that all use the word: \"religion\" (CEFR Level: B1).\n",
      "\n",
      "Rate each sentence from 1 (poor) to 5 (excellent) on the following four criteria:\n",
      "\n",
      "1. Word Usage â€“ Is the word used correctly and meaningfully?\n",
      "2. Clarity â€“ Is the sentence understandable and appropriate for the given CEFR level?\n",
      "3. Grammar â€“ Is the grammar correct and level-appropriate?\n",
      "4. Naturalness â€“ Does the sentence sound natural and fluent (not AI-generated)?\n",
      "\n",
      "âš ï¸ Do not give any explanations or comments.\n",
      "âš ï¸ Just return the ratings in the following format, with no extra output:\n",
      "\n",
      "Sentence A: <Word Usage>, <Clarity>, <Grammar>, <Naturalness>\n",
      "Sentence B: ...\n",
      "Sentence C: ...\n",
      "Sentence D: ...\n",
      "Sentence E: ...\n",
      "Sentence F: ...\n",
      "\n",
      "Sentences:\n",
      "Sentence A: People should respect each other's religion.\n",
      "Sentence B: The new employee has to respect the company's religion policy.\n",
      "Sentence C: Different cultures have their own religion and traditions.\n",
      "Sentence D: Different cultures practice different forms of religion.\n",
      "Sentence E: Her religion is important to her.\n",
      "Sentence F: The religion of Buddhism emphasizes the importance of meditation and compassion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” First Prompt Preview:\\n\")\n",
    "print(task_prompts[27][\"prompt\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8558ff-0948-4aa3-a81f-5028d92138ad",
   "metadata": {},
   "source": [
    "# DeepSeek ile 2 Prompt Testi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19ee3b7-a696-4bf8-808a-9fc8c2971924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prompt 1 (age, A1) ---\n",
      "\n",
      "ğŸŸ¦ Raw Output:\n",
      " Sentence A: 5, 5, 5, 5  \n",
      "Sentence B: 1, 5, 5, 5  \n",
      "Sentence C: 5, 5, 5, 5  \n",
      "Sentence D: 3, 4, 3, 3  \n",
      "Sentence E: 3, 4, 3, 3  \n",
      "Sentence F: 5, 5, 5, 5\n",
      "\n",
      "âœ… Parsed Scores:\n",
      "Sentence A: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence B: {'Word Usage': 1, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence C: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence D: {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3}\n",
      "Sentence E: {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3}\n",
      "Sentence F: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "\n",
      "--- Prompt 2 (animal, A1) ---\n",
      "\n",
      "ğŸŸ¦ Raw Output:\n",
      " Sentence A: 4, 4, 5, 5  \n",
      "Sentence B: 5, 5, 5, 5  \n",
      "Sentence C: 5, 5, 5, 5  \n",
      "Sentence D: 5, 5, 5, 5  \n",
      "Sentence E: 4, 4, 5, 4  \n",
      "Sentence F: 5, 5, 5, 5\n",
      "\n",
      "âœ… Parsed Scores:\n",
      "Sentence A: {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence B: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence C: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence D: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n",
      "Sentence E: {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 4}\n",
      "Sentence F: {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# DeepSeek API key ve base_url\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-9115f967efad41a09f30b761d5f36f53\",\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "# Ä°lk iki prompt (daha Ã¶nce tanÄ±mladÄ±ÄŸÄ±n task_prompts listesi)\n",
    "prompts_to_test = task_prompts[:2]\n",
    "\n",
    "def parse_scores(raw_response):\n",
    "    parsed = {}\n",
    "    lines = raw_response.strip().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        if \":\" in line:\n",
    "            parts = line.split(\":\")\n",
    "            label = parts[0].strip()\n",
    "            scores = [int(s.strip()) for s in parts[1].split(\",\") if s.strip().isdigit()]\n",
    "            if len(scores) == 4:\n",
    "                parsed[label] = {\n",
    "                    \"Word Usage\": scores[0],\n",
    "                    \"Clarity\": scores[1],\n",
    "                    \"Grammar\": scores[2],\n",
    "                    \"Naturalness\": scores[3]\n",
    "                }\n",
    "    return parsed\n",
    "\n",
    "# Test et\n",
    "for i, task in enumerate(prompts_to_test):\n",
    "    print(f\"\\n--- Prompt {i+1} ({task['word']}, {task['level']}) ---\\n\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": task[\"prompt\"]}\n",
    "            ],\n",
    "            temperature=1.0\n",
    "        )\n",
    "\n",
    "        raw_output = response.choices[0].message.content\n",
    "        print(\"ğŸŸ¦ Raw Output:\\n\", raw_output)\n",
    "\n",
    "        parsed = parse_scores(raw_output)\n",
    "        print(\"\\nâœ… Parsed Scores:\")\n",
    "        for sentence, scores in parsed.items():\n",
    "            print(f\"{sentence}: {scores}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Hata:\", e)\n",
    "\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c65bbbe-bf31-48d2-8c17-e66cc0036f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  Model: GPT-4-turbo\n",
      "  ğŸ”¹ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [5] â†’ Avg: 5.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "  ğŸ”¹ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] â†’ Avg: 5.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "\n",
      "ğŸ§  Model: Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf\n",
      "  ğŸ”¹ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [1] â†’ Avg: 1.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "  ğŸ”¹ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [4] â†’ Avg: 4.0\n",
      "    - Clarity: [4] â†’ Avg: 4.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "\n",
      "ğŸ§  Model: Ministral-8B-Instruct-2410.Q4_K_M.gguf\n",
      "  ğŸ”¹ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [5] â†’ Avg: 5.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "  ğŸ”¹ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] â†’ Avg: 5.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "\n",
      "ğŸ§  Model: Claude Sonnet 4\n",
      "  ğŸ”¹ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [3] â†’ Avg: 3.0\n",
      "    - Clarity: [4] â†’ Avg: 4.0\n",
      "    - Grammar: [3] â†’ Avg: 3.0\n",
      "    - Naturalness: [3] â†’ Avg: 3.0\n",
      "  ğŸ”¹ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [4] â†’ Avg: 4.0\n",
      "    - Clarity: [4] â†’ Avg: 4.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [4] â†’ Avg: 4.0\n",
      "\n",
      "ğŸ§  Model: Gemini 2.5 Flash\n",
      "  ğŸ”¹ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [3] â†’ Avg: 3.0\n",
      "    - Clarity: [4] â†’ Avg: 4.0\n",
      "    - Grammar: [3] â†’ Avg: 3.0\n",
      "    - Naturalness: [3] â†’ Avg: 3.0\n",
      "  ğŸ”¹ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] â†’ Avg: 5.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "\n",
      "ğŸ§  Model: Llama-3.2-3B-Instruct-Q4_K_M.gguf\n",
      "  ğŸ”¹ Word: 'age' (Level: A1)\n",
      "    - Word Usage: [5] â†’ Avg: 5.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n",
      "  ğŸ”¹ Word: 'animal' (Level: A1)\n",
      "    - Word Usage: [5] â†’ Avg: 5.0\n",
      "    - Clarity: [5] â†’ Avg: 5.0\n",
      "    - Grammar: [5] â†’ Avg: 5.0\n",
      "    - Naturalness: [5] â†’ Avg: 5.0\n"
     ]
    }
   ],
   "source": [
    "# âœ… Ã–nce DeepSeek'ten dÃ¶nen raw skorlarÄ± hardcoded ÅŸekilde ekleyelim:\n",
    "\n",
    "deepseek_results = {\n",
    "    (\"A1\", \"age\"): {\n",
    "        \"Sentence A\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence B\": {'Word Usage': 1, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence C\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence D\": {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3},\n",
    "        \"Sentence E\": {'Word Usage': 3, 'Clarity': 4, 'Grammar': 3, 'Naturalness': 3},\n",
    "        \"Sentence F\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "    },\n",
    "    (\"A1\", \"animal\"): {\n",
    "        \"Sentence A\": {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence B\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence C\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence D\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "        \"Sentence E\": {'Word Usage': 4, 'Clarity': 4, 'Grammar': 5, 'Naturalness': 4},\n",
    "        \"Sentence F\": {'Word Usage': 5, 'Clarity': 5, 'Grammar': 5, 'Naturalness': 5},\n",
    "    }\n",
    "}\n",
    "\n",
    "# âœ… Model bazlÄ± puanlarÄ± toplayacaÄŸÄ±mÄ±z dict\n",
    "model_scores = {}\n",
    "\n",
    "# âœ… all_tasks iÃ§inden ilgili kelimeleri bul\n",
    "for task in all_tasks:\n",
    "    key = (task[\"level\"], task[\"word\"])\n",
    "    if key not in deepseek_results:\n",
    "        continue\n",
    "\n",
    "    scores_for_task = deepseek_results[key]\n",
    "    mapping = task[\"mapping\"]\n",
    "\n",
    "    for sentence_label, scores in scores_for_task.items():\n",
    "        model_name = mapping[sentence_label][\"model\"]\n",
    "\n",
    "        if model_name not in model_scores:\n",
    "            model_scores[model_name] = {}\n",
    "\n",
    "        if key not in model_scores[model_name]:\n",
    "            model_scores[model_name][key] = {\n",
    "                \"Word Usage\": [],\n",
    "                \"Clarity\": [],\n",
    "                \"Grammar\": [],\n",
    "                \"Naturalness\": []\n",
    "            }\n",
    "\n",
    "        # SkorlarÄ± ekle\n",
    "        for criterion, value in scores.items():\n",
    "            model_scores[model_name][key][criterion].append(value)\n",
    "\n",
    "# âœ… SonuÃ§larÄ± yazdÄ±r\n",
    "for model, words in model_scores.items():\n",
    "    print(f\"\\nğŸ§  Model: {model}\")\n",
    "    for (level, word), criteria in words.items():\n",
    "        print(f\"  ğŸ”¹ Word: '{word}' (Level: {level})\")\n",
    "        for criterion, values in criteria.items():\n",
    "            avg = round(sum(values) / len(values), 2)\n",
    "            print(f\"    - {criterion}: {values} â†’ Avg: {avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e2c9d7-4c25-4c12-a597-85414c273ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ Mapping for 'age' (A1)\n",
      "Sentence A â†’ GPT-4-turbo\n",
      "Sentence B â†’ Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf\n",
      "Sentence C â†’ Ministral-8B-Instruct-2410.Q4_K_M.gguf\n",
      "Sentence D â†’ Claude Sonnet 4\n",
      "Sentence E â†’ Gemini 2.5 Flash\n",
      "Sentence F â†’ Llama-3.2-3B-Instruct-Q4_K_M.gguf\n",
      "\n",
      "ğŸ“Œ Mapping for 'animal' (A1)\n",
      "Sentence A â†’ Llama-3.2-8B-Instruct/Llama-3.2-8B-Instruct-Q4_K_M.gguf\n",
      "Sentence B â†’ Ministral-8B-Instruct-2410.Q4_K_M.gguf\n",
      "Sentence C â†’ Llama-3.2-3B-Instruct-Q4_K_M.gguf\n",
      "Sentence D â†’ Gemini 2.5 Flash\n",
      "Sentence E â†’ Claude Sonnet 4\n",
      "Sentence F â†’ GPT-4-turbo\n"
     ]
    }
   ],
   "source": [
    "# Age ve animal kelimeleri iÃ§in mapping'leri yazdÄ±ralÄ±m\n",
    "for task in all_tasks:\n",
    "    if (task[\"level\"], task[\"word\"]) in [(\"A1\", \"age\"), (\"A1\", \"animal\")]:\n",
    "        print(f\"\\nğŸ“Œ Mapping for '{task['word']}' ({task['level']})\")\n",
    "        for label, info in task[\"mapping\"].items():\n",
    "            print(f\"{label} â†’ {info['model']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7feaa5-8613-437c-a874-9622178f7eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
